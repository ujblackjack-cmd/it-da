"""
ITDA AI Server - FastAPI Main
"""
from dotenv import load_dotenv
import os

# âœ… ê°€ì¥ ë¨¼ì € .env ë¡œë“œ
load_dotenv()

# í™˜ê²½ë³€ìˆ˜ í™•ì¸
print("ğŸ”§ FastAPI ì„œë²„ ì‹œì‘...")
print(f"ğŸ“ OPENAI_API_KEY: {'ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'âŒ ì—†ìŒ'}")
print(f"ğŸ“ SPRING_BOOT_URL: {os.getenv('SPRING_BOOT_URL', 'http://localhost:8080')}")

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from app.api.ai_routes import router as ai_router
from app.api.recommendations import router as recommendations_router
from app.models.model_loader import model_loader
from app.core.logging import logger


# ========================================
# Lifespan Event Handler
# ========================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
    # Startup
    logger.info("ğŸš€ ITDA AI Server ì‹œì‘")

    try:
        model_loader.load_all()
        logger.info("âœ… ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        raise

    yield  # ì„œë²„ ì‹¤í–‰ ì¤‘

    # Shutdown
    logger.info("ğŸ‘‹ ITDA AI Server ì¢…ë£Œ")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="ITDA AI Server",
    description="ëª¨ì„ ì¶”ì²œ AI ì„œë²„ (SVD, LightGBM Ranker, KcELECTRA)",
    version="2.0.0",
    lifespan=lifespan
)

# ========================================
# âœ… CORS ì„¤ì • (ë§¤ìš° ì¤‘ìš”!)
# ========================================

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",      # React ê°œë°œ ì„œë²„
        "http://localhost:5173",      # Vite ê°œë°œ ì„œë²„
        "http://127.0.0.1:3000",
        "http://127.0.0.1:5173",
    ],
    allow_credentials=True,
    allow_methods=["*"],              # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš©
    allow_headers=["*"],              # ëª¨ë“  í—¤ë” í—ˆìš©
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(recommendations_router)
app.include_router(ai_router)

@app.get("/")
async def root():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "ok",
        "message": "ITDA AI Server is running",
        "version": "2.0.0",
        "models": model_loader.get_status()
    }

# ========================================
# ì„œë²„ ì‹¤í–‰
# ========================================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )