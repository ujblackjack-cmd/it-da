"""
LightGBM Ranker Model Wrapper - ê²½ê³  ì™„ì „ ì°¨ë‹¨
"""

import json
import pickle
import os
import sys
import warnings
from pathlib import Path
from typing import Optional, Any
from contextlib import contextmanager
import numpy as np


@contextmanager
def suppress_stdout_stderr():
    """stdout/stderrë¥¼ ì™„ì „ížˆ ì°¨ë‹¨"""
    with open(os.devnull, 'w') as devnull:
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        sys.stdout = devnull
        sys.stderr = devnull
        try:
            yield
        finally:
            sys.stdout = old_stdout
            sys.stderr = old_stderr


class LightGBMRankerModel:
    def __init__(self, model_path: str = "models/lightgbm_ranker.pkl", calib_path: Optional[str] = None):
        self.model_path = Path(model_path)
        self.calib_path = Path(calib_path) if calib_path else None

        self.model: Optional[Any] = None
        self.calibration: Optional[dict] = None
        self.scaler = None
        self.feature_names = []
        self.model_type: Optional[str] = None
        self.schema_version: Optional[str] = None

        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ['LIGHTGBM_VERBOSITY'] = '-1'
        warnings.filterwarnings('ignore')

    def load(self):
        """ëª¨ë¸ ë¡œë“œ"""
        if not self.model_path.exists():
            raise FileNotFoundError(f"Model not found: {self.model_path}")

        print(f"ðŸ“¦ LightGBM Ranker ë¡œë”© ì¤‘: {self.model_path}")

        with open(self.model_path, "rb") as f:
            loaded = pickle.load(f)

        # ìƒˆ í˜•ì‹
        if isinstance(loaded, dict) and "model" in loaded:
            self.model = loaded["model"]
            self.feature_names = loaded.get("feature_names", [])
            self.schema_version = loaded.get("schema_version")
            self.scaler = loaded.get("scaler")
            self.model_type = "dict_model_bundle"
            print(f"  âœ… ìƒˆ í˜•ì‹ ëª¨ë¸ ë¡œë“œ (schema: {self.schema_version})")

        # êµ¬ í˜•ì‹
        elif isinstance(loaded, dict) and "ranker" in loaded:
            self.model = loaded["ranker"]
            self.scaler = loaded.get("scaler")
            self.feature_names = loaded.get("feature_names", [])
            self.model_type = "dict_ranker_bundle"
            print(f"  âœ… êµ¬ í˜•ì‹ ëª¨ë¸ ë¡œë“œ")

        # ì§ì ‘ ëª¨ë¸
        else:
            self.model = loaded
            self.model_type = "direct_model"
            print(f"  âœ… ì§ì ‘ ëª¨ë¸ ë¡œë“œ")

        # verbose ì„¤ì •
        if hasattr(self.model, 'set_params'):
            self.model.set_params(verbose=-1)

        # calibration ë¡œë“œ
        if self.calib_path and self.calib_path.exists():
            with open(self.calib_path, "r", encoding="utf-8") as f:
                self.calibration = json.load(f)
            print(f"  âœ… Calibration ë¡œë“œ: {self.calib_path}")

        print(
            f"âœ… LightGBM Ranker ë¡œë“œ ì™„ë£Œ! "
            f"(type={self.model_type}, features={len(self.feature_names)}, "
            f"calib={'yes' if self.calibration else 'no'})"
        )

    def predict(self, X: np.ndarray) -> np.ndarray:
        """ì˜ˆì¸¡ ìˆ˜í–‰ - ê²½ê³  ì°¨ë‹¨"""
        if self.model is None:
            raise ValueError("Model not loaded. Call load() first.")

        if self.scaler is not None:
            X = self.scaler.transform(X)

        # â­ stdout ë¦¬ë‹¤ì´ë ‰ì…˜ìœ¼ë¡œ ê²½ê³  ì°¨ë‹¨
        with suppress_stdout_stderr():
            predictions = self.model.predict(X)

        return predictions

    def predict_single(self, features: np.ndarray) -> float:
        """ë‹¨ì¼ ìƒ˜í”Œ ì˜ˆì¸¡"""
        if features.ndim == 1:
            features = features.reshape(1, -1)
        return float(self.predict(features)[0])

    def is_loaded(self) -> bool:
        return self.model is not None

    def get_info(self) -> dict:
        return {
            "loaded": self.is_loaded(),
            "model_type": self.model_type,
            "schema_version": self.schema_version,
            "n_features": len(self.feature_names),
            "feature_names": self.feature_names[:10] if self.feature_names else [],
            "has_scaler": self.scaler is not None,
            "has_calibration": self.calibration is not None,
        }