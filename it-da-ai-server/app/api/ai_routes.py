"""
AI Routes for Spring Boot Integration
"""

from fastapi import APIRouter, HTTPException,Depends
from pydantic import BaseModel, Field
from typing import List, Dict, Optional
from app.models.model_loader import model_loader
from app.core.logging import logger
from typing import Dict
from app.schemas.ai_schemas import AISearchRequest, AISearchResponse
from app.services.gpt_prompt_service import GPTPromptService
from app.services.AIRecommendationService import AIRecommendationService
import math
import uuid
import os

router = APIRouter(prefix="/api/ai/recommendations", tags=["AI"])

# ========================================
# Request/Response Models (Spring Boot í˜¸í™˜)
# ========================================

class RecommendRequest(BaseModel):
    user_id: int
    top_n: int = 10

class RecommendResponse(BaseModel):
    user_id: int
    recommended_meetings: List[Dict]  # [{"meeting_id": 1, "predicted_score": 4.5, "rank": 1}]
    total_count: int

class SatisfactionRequest(BaseModel):
    user_id: int
    meeting_id: int
    # Spring Bootì—ì„œ ì „ë‹¬ë°›ì„ ì‚¬ìš©ì/ëª¨ì„ ì •ë³´
    user_lat: float
    user_lng: float
    user_interests: str
    user_time_preference: str
    user_location_pref: str
    user_budget_type: str
    user_avg_rating: float
    user_meeting_count: int
    user_rating_std: float
    meeting_lat: float
    meeting_lng: float
    meeting_category: str
    meeting_subcategory: str
    meeting_time_slot: str
    meeting_location_type: str
    meeting_vibe: str
    meeting_max_participants: int
    meeting_expected_cost: int
    meeting_avg_rating: Optional[float] = 0.0
    meeting_rating_count: int = 0
    meeting_participant_count: int = 0

class SatisfactionResponse(BaseModel):
    user_id: int
    meeting_id: int
    predicted_rating: float
    rating_stars: str
    satisfaction_level: str
    recommended: bool
    reasons: List[Dict]  # [{"icon": "ğŸ“", "text": "..."}]

class SentimentRequest(BaseModel):
    text: str

class SentimentResponse(BaseModel):
    text: str
    sentiment: str
    score: float
    probabilities: Dict[str, float]

class CentroidRequest(BaseModel):
    user_locations: List[Dict[str, float]]  # [{"latitude": 37.5, "longitude": 127.0}]

class CentroidResponse(BaseModel):
    centroid: Dict[str, float]
    address: Optional[str] = None

class PlaceRecommendRequest(BaseModel):
    participants: List[Dict]  # [{"user_id": 1, "latitude": 37.5, "longitude": 127.0}]
    category: Optional[str] = "ì¹´í˜"
    max_distance: Optional[float] = 3.0

class PlaceRecommendResponse(BaseModel):
    success: bool
    centroid: Dict[str, float]
    search_radius: float
    recommendations: List[Dict]
    filtered_count: Dict[str, int]
    processing_time_ms: int

# ========================================
# Utility Functions
# ========================================

def clamp(v: float, lo: float, hi: float) -> float:
    return max(lo, min(hi, v))

def score_to_rating(score: float) -> float:
    """Raw score â†’ 1~5 í‰ì  ë³€í™˜"""
    s = 1.0 / (1.0 + math.exp(-score))
    return round(clamp(1.0 + 4.0 * s, 1.0, 5.0), 1)

def rating_to_stars(rating: float) -> str:
    """í‰ì  â†’ ë³„ ë¬¸ìì—´"""
    full_stars = int(rating)
    half_star = 1 if (rating - full_stars) >= 0.5 else 0
    return "â­" * full_stars + ("â­" if half_star else "")

def get_satisfaction_level(rating: float) -> str:
    """ë§Œì¡±ë„ ë ˆë²¨"""
    if rating >= 4.5:
        return "VERY_HIGH"
    elif rating >= 3.5:
        return "HIGH"
    elif rating >= 2.5:
        return "MEDIUM"
    else:
        return "LOW"

def build_reasons(feat: dict) -> List[Dict]:
    """ë§Œì¡±ë„ ì˜ˆì¸¡ ì´ìœ  ìƒì„±"""
    reasons = []

    if feat.get("distance_km", 999) <= 3:
        reasons.append({
            "icon": "ğŸ“",
            "text": f"ì§‘ì—ì„œ {feat['distance_km']:.1f}kmë¡œ ê°€ê¹Œì›Œìš”"
        })

    if feat.get("time_match", 0) == 1.0:
        reasons.append({
            "icon": "â°",
            "text": "ì„ í˜¸í•˜ëŠ” ì‹œê°„ëŒ€ì™€ ì˜ ë§ì•„ìš”"
        })

    if feat.get("location_type_match", 0) == 1.0:
        reasons.append({
            "icon": "ğŸ ",
            "text": "ì‹¤ë‚´/ì•¼ì™¸ ì„ í˜¸ì™€ ì¼ì¹˜í•´ìš”"
        })

    if feat.get("cost_match_score", 0.5) >= 0.7:
        reasons.append({
            "icon": "ğŸ’°",
            "text": "ì˜ˆì‚° ì„±í–¥ì— ì˜ ë§ëŠ” ë¹„ìš©ì´ì—ìš”"
        })

    if feat.get("interest_match_score", 0) >= 0.5:
        reasons.append({
            "icon": "âœ¨",
            "text": "ê´€ì‹¬ì‚¬ì™€ ì¹´í…Œê³ ë¦¬ê°€ ì˜ ë§ì•„ìš”"
        })

    return reasons[:3]

# ========================================
# Dependency Injection
# ========================================

def get_gpt_service() -> GPTPromptService:
    """GPT ì„œë¹„ìŠ¤ ì˜ì¡´ì„±"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise HTTPException(status_code=500, detail="OPENAI_API_KEY not configured")
    return GPTPromptService(api_key=api_key)

def get_ai_recommendation_service(
    gpt_service: GPTPromptService = Depends(get_gpt_service)
) -> AIRecommendationService:
    """AI ì¶”ì²œ ì„œë¹„ìŠ¤ ì˜ì¡´ì„±"""
    spring_boot_url = os.getenv("SPRING_BOOT_URL", "http://localhost:8080")
    return AIRecommendationService(gpt_service, spring_boot_url)


# ========================================
# API Endpoints
# ========================================

@router.get("/health")
async def health_check():
    """
    AI ì„œë²„ í—¬ìŠ¤ì²´í¬
    GET /api/ai/recommendations/health
    """
    return {
        "status": "ok",
        "message": "ITDA AI Server is running",
        "models": model_loader.get_status()
    }


@router.get("/meetings")
async def recommend_meetings(user_id: int, top_n: int = 10):
    try:
        logger.info(f"ğŸ¤– AI ì¶”ì²œ ìš”ì²­: user_id={user_id}, top_n={top_n}")

        if not model_loader.svd or not model_loader.svd.is_loaded():
            logger.error("âŒ SVD ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            raise HTTPException(status_code=503, detail="SVD ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        if top_n > 50:
            top_n = 50

        recommendations = await model_loader.svd.recommend(user_id=user_id, top_n=top_n)
        logger.info(f"âœ… SVD ì¶”ì²œ ì™„ë£Œ: {len(recommendations)}ê°œ")

        # Spring DTO(RecommendedMeeting.score) ì— ë§ì¶”ê¸°: score í‚¤ë¡œ!
        rec_list = [
            {
                "meeting_id": int(meeting_id),
                "score": round(float(score), 4),   # âœ… predicted_score -> score
                "rank": idx + 1
            }
            for idx, (meeting_id, score) in enumerate(recommendations)
        ]

        return {
            "success": True,                 # âœ… ì¶”ê°€ (NPE ë°©ì§€ + ì˜ë¯¸ ë§ìŒ)
            "user_id": user_id,
            "recommendations": rec_list,     # âœ… recommended_meetings -> recommendations
            "model_info": {                  # âœ… ìˆìœ¼ë©´ ì¢‹ìŒ. ì—†ìœ¼ë©´ nullë¡œë¼ë„
                "rmse": None,
                "mae": None,
                "accuracy": None
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        # ì‹¤íŒ¨ ì‘ë‹µë„ success ë„£ì–´ì£¼ë©´ Springì´ ì•ˆì •ì 
        raise HTTPException(status_code=500, detail=f"ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")

@router.get("/models")
async def get_models_info():
    """
    AI ëª¨ë¸ ì •ë³´
    GET /api/ai/recommendations/models
    """
    return {
        "models": model_loader.get_status(),
        "svd": {
            "loaded": model_loader.svd.is_loaded() if model_loader.svd else False,
            "user_count": len(model_loader.svd.user_ids) if model_loader.svd and model_loader.svd.user_ids else 0,
            "meeting_count": len(model_loader.svd.meeting_ids) if model_loader.svd and model_loader.svd.meeting_ids else 0
        } if model_loader.svd else {},
        "lightgbm": {
            "loaded": model_loader.lightgbm.is_loaded() if model_loader.lightgbm else False,
            "feature_count": len(model_loader.feature_builder.get_feature_names()) if model_loader.feature_builder else 0
        } if model_loader.lightgbm else {},
        "kcelectra": {
            "loaded": model_loader.kcelectra.is_loaded() if model_loader.kcelectra else False,
            "device": model_loader.kcelectra.device if model_loader.kcelectra else "unknown"
        } if model_loader.kcelectra else {}
    }


@router.get("/meetings")
async def recommend_meetings(user_id: int, top_n: int = 10):
    """
    SVD í˜‘ì—… í•„í„°ë§ ëª¨ì„ ì¶”ì²œ (ì‹¤ì‹œê°„ DB ì—°ë™)
    GET /api/ai/recommendations/meetings?userId=3&topN=10
    """
    try:
        if not model_loader.svd or not model_loader.svd.is_loaded():
            raise HTTPException(status_code=503, detail="SVD ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        # topN ì œí•œ
        if top_n > 50:
            top_n = 50

        # SVD ì¶”ì²œ (ì‹¤ì‹œê°„ DB ì¡°íšŒ)
        recommendations = await model_loader.svd.recommend(
            user_id=user_id,
            top_n=top_n
        )

        # ì‘ë‹µ ìƒì„±
        recommended_meetings = [
            {
                "meeting_id": int(meeting_id),
                "predicted_score": round(float(score), 4),
                "rank": idx + 1
            }
            for idx, (meeting_id, score) in enumerate(recommendations)
        ]

        return {
            "user_id": user_id,
            "recommended_meetings": recommended_meetings,
            "total_count": len(recommended_meetings)
        }

    except Exception as e:
        logger.error(f"ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/recommend")
async def recommend_meetings_post(request: RecommendRequest):
    """
    SVD í˜‘ì—… í•„í„°ë§ ëª¨ì„ ì¶”ì²œ (POST)
    POST /api/ai/recommendations/recommend
    """
    try:
        if not model_loader.svd or not model_loader.svd.is_loaded():
            raise HTTPException(status_code=503, detail="SVD ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        # SVD ì¶”ì²œ
        recommendations = model_loader.svd.recommend(
            user_id=request.user_id,
            top_n=request.top_n
        )

        # ì‘ë‹µ ìƒì„±
        recommended_meetings = [
            {
                "meeting_id": int(meeting_id),
                "predicted_score": round(float(score), 4),
                "rank": idx + 1
            }
            for idx, (meeting_id, score) in enumerate(recommendations)
        ]

        return {
            "user_id": request.user_id,
            "recommended_meetings": recommended_meetings,
            "total_count": len(recommended_meetings)
        }

    except Exception as e:
        logger.error(f"ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/satisfaction")
async def predict_satisfaction_get(user_id: int, meeting_id: int):
    """
    LightGBM Ranker ë§Œì¡±ë„ ì˜ˆì¸¡ (GET)
    GET /api/ai/recommendations/satisfaction?userId=3&meetingId=15

    Spring Bootì—ì„œ ì‚¬ìš©ì/ëª¨ì„ ì •ë³´ë¥¼ ì¡°íšŒí•˜ì—¬ í˜¸ì¶œí•´ì•¼ í•¨
    """
    # Spring Bootê°€ ì´ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì§€ ì•ŠìŒ
    # Spring Boot Serviceì—ì„œ POSTë¡œ í˜¸ì¶œ
    raise HTTPException(status_code=501, detail="Use POST /satisfaction with full data")


@router.post("/satisfaction")
async def predict_satisfaction(request: SatisfactionRequest):
    """
    LightGBM Ranker ë§Œì¡±ë„ ì˜ˆì¸¡
    """
    try:
        if not model_loader.lightgbm or not model_loader.lightgbm.is_loaded():
            raise HTTPException(status_code=503, detail="LightGBM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        if not model_loader.feature_builder:
            raise HTTPException(status_code=503, detail="FeatureBuilderê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        # ì‚¬ìš©ì ì •ë³´ êµ¬ì„±
        user = {
            "lat": request.user_lat,
            "lng": request.user_lng,
            "interests": request.user_interests,
            "time_preference": request.user_time_preference,
            "user_location_pref": request.user_location_pref,
            "budget_type": request.user_budget_type,
            "user_avg_rating": request.user_avg_rating,
            "user_meeting_count": request.user_meeting_count,
            "user_rating_std": request.user_rating_std,
        }

        # ëª¨ì„ ì •ë³´ êµ¬ì„±
        meeting = {
            "lat": request.meeting_lat,
            "lng": request.meeting_lng,
            "category": request.meeting_category,
            "subcategory": request.meeting_subcategory,
            "time_slot": request.meeting_time_slot,
            "meeting_location_type": request.meeting_location_type,
            "vibe": request.meeting_vibe,
            "max_participants": request.meeting_max_participants,
            "expected_cost": request.meeting_expected_cost,
            "meeting_avg_rating": request.meeting_avg_rating or 0.0,
            "meeting_rating_count": request.meeting_rating_count,
            "meeting_participant_count": request.meeting_participant_count,
        }

        # íŠ¹ì§• ì¶”ì¶œ
        feat, x = model_loader.feature_builder.build(user, meeting)

        # ì˜ˆì¸¡
        pred = model_loader.lightgbm.predict(x)[0]
        predicted_rating = score_to_rating(float(pred))

        return {
            "user_id": request.user_id,
            "meeting_id": request.meeting_id,
            "predicted_rating": predicted_rating,
            "rating_stars": rating_to_stars(predicted_rating),
            "satisfaction_level": get_satisfaction_level(predicted_rating),
            "recommended": predicted_rating >= 3.5,
            "reasons": build_reasons(feat)
        }

    except Exception as e:
        logger.error(f"ë§Œì¡±ë„ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/sentiment")
async def analyze_sentiment(request: SentimentRequest):
    """
    KcELECTRA ê°ì„± ë¶„ì„
    """
    try:
        if not model_loader.kcelectra or not model_loader.kcelectra.is_loaded():
            raise HTTPException(status_code=503, detail="KcELECTRA ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        # ê°ì„± ë¶„ì„
        result = model_loader.kcelectra.predict(request.text)

        return result

    except Exception as e:
        logger.error(f"ê°ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/centroid")
async def calculate_centroid(request: CentroidRequest):
    """
    ì¤‘ê°„ì§€ì  ê³„ì‚°
    """
    try:
        locations = request.user_locations

        if not locations:
            raise HTTPException(status_code=400, detail="ìœ„ì¹˜ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

        # í‰ê·  ê³„ì‚°
        avg_lat = sum(loc["latitude"] for loc in locations) / len(locations)
        avg_lng = sum(loc["longitude"] for loc in locations) / len(locations)

        return {
            "centroid": {
                "latitude": round(avg_lat, 6),
                "longitude": round(avg_lng, 6)
            },
            "address": None  # TODO: Kakao Maps API ì—°ë™
        }

    except Exception as e:
        logger.error(f"ì¤‘ê°„ì§€ì  ê³„ì‚° ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/place")
async def recommend_place_get(meeting_id: int):
    """
    ì¥ì†Œ ì¶”ì²œ (GET)
    GET /api/ai/recommendations/place?meetingId=15

    Spring Bootê°€ ì´ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì§€ ì•ŠìŒ
    Spring Boot Serviceì—ì„œ POSTë¡œ í˜¸ì¶œ
    """
    raise HTTPException(status_code=501, detail="Use POST /place with full data")


@router.post("/place")
async def recommend_place(request: PlaceRecommendRequest):
    """
    ì¥ì†Œ ì¶”ì²œ (Kakao Maps ì—°ë™ í•„ìš”)
    """
    try:
        # ì¤‘ê°„ì§€ì  ê³„ì‚°
        locations = [
            {"latitude": p["latitude"], "longitude": p["longitude"]}
            for p in request.participants
        ]

        avg_lat = sum(loc["latitude"] for loc in locations) / len(locations)
        avg_lng = sum(loc["longitude"] for loc in locations) / len(locations)

        centroid = {"latitude": round(avg_lat, 6), "longitude": round(avg_lng, 6)}

        # TODO: Kakao Maps APIë¡œ ì£¼ë³€ ì¥ì†Œ ê²€ìƒ‰

        return {
            "success": True,
            "centroid": centroid,
            "search_radius": request.max_distance * 1000,  # km â†’ m
            "recommendations": [],  # TODO: Kakao Maps ê²°ê³¼
            "filtered_count": {"total": 0, "within_radius": 0, "returned": 0},
            "processing_time_ms": 0
        }

    except Exception as e:
        logger.error(f"ì¥ì†Œ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/search", response_model=AISearchResponse)

async def ai_search(
        request: AISearchRequest,
        ai_service: AIRecommendationService = Depends(get_ai_recommendation_service)
):
    """
    GPT ê¸°ë°˜ AI ê²€ìƒ‰ ë° ì¶”ì²œ

    POST /api/ai/search

    Request Body:
    {
        "user_prompt": "ì˜¤ëŠ˜ ì €ë… ê°•ë‚¨ì—ì„œ ëŸ¬ë‹í•  ì‚¬ëŒ~",
        "user_id": 3,
        "top_n": 5
    }

    Response:
    {
        "user_prompt": "...",
        "parsed_query": {
            "category": "ìŠ¤í¬ì¸ ",
            "subcategory": "ëŸ¬ë‹",
            "time_slot": "evening",
            "location_query": "ê°•ë‚¨",
            ...
        },
        "total_candidates": 42,
        "recommendations": [
            {
                "meeting_id": 42,
                "title": "í•œê°• ì„ ì…‹ ëŸ¬ë‹",
                "match_score": 96,
                "predicted_rating": 4.8,
                "key_points": [...],
                "reasoning": "..."
            }
        ]
    }
    """

    rid = str(uuid.uuid4())[:8]
    logger.info(f"[RID={rid}] ğŸ” AI ê²€ìƒ‰ ìš”ì²­: user_id={request.user_id}, prompt='{request.user_prompt}'")

    try:
        logger.info(f"ğŸ” AI ê²€ìƒ‰ ìš”ì²­: user_id={request.user_id}, prompt='{request.user_prompt}'")

        result = await ai_service.get_ai_recommendations(
            user_prompt=request.user_prompt,
            user_id=request.user_id,
            top_n=request.top_n
        )

        logger.info(f"âœ… AI ê²€ìƒ‰ ì™„ë£Œ: {len(result['recommendations'])}ê°œ ì¶”ì²œ")

        return result

    except Exception as e:
        logger.error(f"âŒ AI ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/parse-prompt")
async def parse_prompt(
        prompt: str,
        gpt_service: GPTPromptService = Depends(get_gpt_service)
):
    """
    GPT í”„ë¡¬í”„íŠ¸ íŒŒì‹± í…ŒìŠ¤íŠ¸

    GET /api/ai/parse-prompt?prompt=ì˜¤ëŠ˜ ì €ë… ê°•ë‚¨ì—ì„œ ëŸ¬ë‹í•  ì‚¬ëŒ
    """
    try:
        parsed = await gpt_service.parse_search_query(prompt)
        return {
            "prompt": prompt,
            "parsed": parsed
        }
    except Exception as e:
        logger.error(f"âŒ í”„ë¡¬í”„íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
