"""
AI Recommendation Service (í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°)
GPT íŒŒì‹± â†’ DB ê²€ìƒ‰ â†’ AI ëª¨ë¸ ì¶”ì²œ í†µí•©
"""

import httpx
import uuid
from typing import List, Dict, Optional

from app.core.logging import logger
from app.services.gpt_prompt_service import GPTPromptService
from app.models.model_loader import model_loader

# Query ëª¨ë“ˆ
from app.services.query import QueryNormalizer, QueryPostProcessor, QueryBuilder

# Search ëª¨ë“ˆ
from app.services.search import SearchStrategy, MeetingSearchService

# Scoring ëª¨ë“ˆ
from app.services.scoring import MeetingScorer, IntentAdjuster

# Intent ëª¨ë“ˆ
from app.services.intent import IntentDetector

# Fallback ëª¨ë“ˆ
from app.services.fallback import SVDRecommender, ReasoningGenerator

# Utils ëª¨ë“ˆ
from app.services.utils import QueryTermExtractor


class AIRecommendationService:
    """AI ì¶”ì²œ í†µí•© ì„œë¹„ìŠ¤ - ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""

    # ê°œì¸ ê°ì • í‘œí˜„ í‚¤ì›Œë“œ (í´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ì´ë™)
    PERSONAL_EMOTIONS = {
        "love": ["ì‚¬ë‘í•´", "ì¢‹ì•„í•´", "ì˜ˆë»", "ì´ë»", "ë©‹ì ¸", "ìµœê³ "],
        "praise": ["ì˜í–ˆì–´", "ëŒ€ë‹¨í•´", "í›Œë¥­í•´", "ë©‹ìˆì–´"],
        "random": ["ë™ì›ì´", "ì§„ìš°", "í´ë¡œë“œ"],  # ì´ë¦„
        "body_part": ["ë°œê°€ë½", "ì†ê°€ë½", "ë¨¸ë¦¬ì¹´ë½", "ë¬´ë¦"],  # ì‹ ì²´ ë¶€ìœ„ (í™œë™ ë¬´ê´€)
    }

    def __init__(
        self,
        gpt_service: GPTPromptService,
        spring_boot_url: str = "http://localhost:8080"
    ):
        """
        Args:
            gpt_service: GPT ì„œë¹„ìŠ¤
            spring_boot_url: Spring Boot API URL
        """
        self.gpt_service = gpt_service
        self.spring_boot_url = spring_boot_url

        # Query ëª¨ë“ˆ
        self.normalizer = QueryNormalizer()
        self.postprocessor = QueryPostProcessor(self.normalizer)
        self.query_builder = QueryBuilder(self.normalizer)

        # Search ëª¨ë“ˆ
        self.search_strategy = SearchStrategy()
        self.search_service = MeetingSearchService(
            spring_boot_url=spring_boot_url,
            query_builder=self.query_builder,
            search_strategy=self.search_strategy,
            normalizer=self.normalizer
        )

        # Scoring ëª¨ë“ˆ
        self.intent_detector = IntentDetector()
        self.intent_adjuster = IntentAdjuster(self.normalizer)
        self.scorer = MeetingScorer(
            model_loader=model_loader,
            normalizer=self.normalizer,
            intent_adjuster=self.intent_adjuster
        )

        # Fallback ëª¨ë“ˆ
        self.svd_recommender = SVDRecommender(
            model_loader=model_loader,
            spring_boot_url=spring_boot_url
        )
        self.reasoning_generator = ReasoningGenerator(gpt_service)

        # Utils
        self.query_term_extractor = QueryTermExtractor()

    async def get_ai_recommendations(
        self,
        user_prompt: str,
        user_id: int,
        top_n: int = 5
    ) -> Dict:
        """
        AI ê¸°ë°˜ ëª¨ì„ ì¶”ì²œ (ë©”ì¸ íŒŒì´í”„ë¼ì¸)

        Args:
            user_prompt: ìœ ì € ì…ë ¥ í”„ë¡¬í”„íŠ¸
            user_id: ìœ ì € ID
            top_n: ì¶”ì²œ ê°œìˆ˜

        Returns:
            ì¶”ì²œ ê²°ê³¼
        """
        rid = str(uuid.uuid4())[:8]
        logger.info(f"[RID={rid}] ğŸ” AI ê²€ìƒ‰ ìš”ì²­: user_id={user_id}, prompt='{user_prompt}'")

        try:
            # ==========================================
            # Step 1: GPT íŒŒì‹±
            # ==========================================
            parsed_query = await self.gpt_service.parse_search_query(user_prompt)

            # âœ… ê°ì • ì „ìš© ê²€ìƒ‰ì–´ í›„ì²˜ë¦¬
            emotion_keywords = ["íë§", "ì§œì¦", "ì‹ ë‚œ", "ì—¬ìœ ", "í¸ì•ˆ", "í”¼ê³¤", "ìš°ìš¸"]
            is_emotion_only = any(kw in user_prompt for kw in emotion_keywords)

            if is_emotion_only and parsed_query.get("vibe") and parsed_query.get("category"):
                logger.info(f"[POST_FIX] ê°ì • ì „ìš© ê²€ìƒ‰ ê°ì§€: '{user_prompt}' â†’ category '{parsed_query['category']}' ì œê±°")
                parsed_query["category"] = None
                parsed_query["emotion_only_search"] = True

            # Taxonomy êµì •
            parsed_query = self.normalizer.normalize_taxonomy(parsed_query)

            # Post-processing (ë°°ê³ íŒŒ, ì‚¬ì§„, ë‡Œ, ì¶¤, ê°ì • ë“±)
            parsed_query = self.postprocessor.post_fix(user_prompt, parsed_query)

            # Category ì¦ê±° ê¸°ë°˜ ê°€ë“œ
            parsed_query = self.postprocessor.guard_category_by_evidence(user_prompt, parsed_query)

            # Vibe prior ì ìš©
            parsed_query = self.normalizer.apply_vibe_prior(parsed_query)

            # Vibe ì •ê·œí™”
            parsed_query["vibe"] = self.normalizer.normalize_vibe(parsed_query.get("vibe"))

            # ==========================================
            # Step 2: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ
            # ==========================================
            user_context = await self._get_user_context(user_id)
            logger.info(f"[CTX] lat={user_context.get('latitude')} lng={user_context.get('longitude')}")

            # ==========================================
            # Step 2.5: ê°œì¸ ê°ì • í‘œí˜„ ì²´í¬
            # ==========================================
            if self._is_personal_emotion(user_prompt, parsed_query):
                logger.warning(f"âš ï¸ ê°œì¸ ê°ì • í‘œí˜„ ê°ì§€: '{user_prompt}' â†’ clarification")

                clarification_card = self._make_clarification_card(
                    user_prompt, parsed_query, user_context
                )

                return {
                    "user_prompt": user_prompt,
                    "parsed_query": parsed_query,
                    "total_candidates": 0,
                    "recommendations": [clarification_card],
                    "search_trace": {
                        "steps": [],
                        "final_level": 0,
                        "final_label": "PERSONAL_EMOTION_CLARIFICATION",
                        "fallback": False
                    }
                }

            # ==========================================
            # Step 2.6: ì´ˆì• ë§¤ ì¼€ì´ìŠ¤ ì²´í¬
            # ==========================================
            kw = parsed_query.get("keywords") or []
            conf = float(parsed_query.get("confidence", 0) or 0)
            cat = parsed_query.get("category")
            sub = parsed_query.get("subcategory")
            vibe = parsed_query.get("vibe")
            ts = parsed_query.get("time_slot")
            loc_q = parsed_query.get("location_query")

            # ì´ˆì• ë§¤ ì¼€ì´ìŠ¤: SVD + Clarification
            if conf < 0.6 and len(kw) == 0 and not cat and not sub and not vibe and not ts and not loc_q:
                logger.warning(f"âš ï¸ ì´ˆì• ë§¤ ê²€ìƒ‰ì–´ ê°ì§€ (conf={conf:.2f}): '{user_prompt}' â†’ SVD fallback + clarification")

                svd_data = await self.svd_recommender.recommend(
                    user_id, user_prompt, parsed_query, top_n, user_context
                )

                clarification_card = self._make_clarification_card(user_prompt, parsed_query, user_context)

                recommendations = svd_data.get("recommendations", [])[:top_n]
                recommendations.append(clarification_card)

                return {
                    "user_prompt": user_prompt,
                    "parsed_query": parsed_query,
                    "total_candidates": svd_data.get("total_candidates", 0),
                    "recommendations": recommendations,
                    "search_trace": {
                        "steps": [],
                        "final_level": 0,
                        "final_label": "SVD_FALLBACK_WITH_CLARIFY",
                        "fallback": True
                    }
                }

            # ==========================================
            # Step 3: ì¿¼ë¦¬ ë³´ê°• (GPT)
            # ==========================================
            enriched_query = await self.gpt_service.enrich_with_user_context(parsed_query, user_context)

            # âœ… ğŸ”¥ ê²€ìƒ‰ ì „ì— ìµœì¢… ì²´í¬!
            emotion_keywords = ["íë§", "ì§œì¦", "ì‹ ë‚œ", "ì—¬ìœ ", "í¸ì•ˆ", "í”¼ê³¤", "ìš°ìš¸"]
            is_emotion_only = any(kw in user_prompt for kw in emotion_keywords)

            if is_emotion_only and enriched_query.get("vibe"):
                activity_keywords = [
                    "ì¹´í˜", "ë§›ì§‘", "ì¶•êµ¬", "ëŸ¬ë‹", "ì „ì‹œ", "ê³µì—°",
                    "ìŠ¤í„°ë””", "ê³µë¶€", "ìš”ê°€", "ëª…ìƒ", "ë³¼ë§", "ë°©íƒˆì¶œ"
                ]
                has_activity = any(kw in user_prompt for kw in activity_keywords)

                if not has_activity:
                    logger.info(f"[FINAL_FIX] ê°ì • ì „ìš© ì¬í™•ì •: category ê°•ì œ ì œê±°!")
                    enriched_query["category"] = None
                    enriched_query["subcategory"] = None
                    enriched_query["emotion_only_search"] = True

            # ==========================================
            # Step 4: ê²€ìƒ‰ (Relaxation)
            # ==========================================
            trace_steps: list = []
            base_query = self.search_strategy.pre_relax_query_by_conf(enriched_query)

            logger.info(f"ğŸ”¥ğŸ”¥ğŸ”¥ [DEBUG] base_query í™•ì¸: {base_query}")
            logger.info(f"ğŸ”¥ğŸ”¥ğŸ”¥ [DEBUG] _search_with_relaxation í˜¸ì¶œ ì§ì „!")

            candidate_meetings = await self.search_service.search_with_relaxation(
                base_query, user_context, trace_steps, user_prompt
            )

            logger.info(f"ğŸ”¥ğŸ”¥ğŸ”¥ [DEBUG] _search_with_relaxation ì™„ë£Œ!")
            logger.info(f"ğŸ”¥ğŸ”¥ğŸ”¥ [DEBUG] candidate_meetings ê°œìˆ˜: {len(candidate_meetings) if candidate_meetings else 0}")

            # ==========================================
            # Step 4.5: ê²€ìƒ‰ ê²°ê³¼ ì—†ìœ¼ë©´ SVD fallback
            # ==========================================
            if not candidate_meetings:
                logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - SVD ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ ëŒ€ì²´")
                data = await self.svd_recommender.recommend(
                    user_id, user_prompt, parsed_query, top_n, user_context
                )

                # Intent ë³´ì •
                intent = self.intent_detector.detect(user_prompt, enriched_query)

                for rec in data.get("recommendations", []):
                    adjustment = self.intent_adjuster.adjust(intent, rec, enriched_query)
                    new_score = rec.get("match_score", 0) + adjustment
                    rec["match_score"] = int(max(0, min(100, new_score)))
                    rec["intent"] = intent

                data["search_trace"] = {
                    "steps": trace_steps,
                    "final_level": trace_steps[-1]["level"] if trace_steps else 0,
                    "final_label": trace_steps[-1]["label"] if trace_steps else "L0 ì›ë³¸",
                    "fallback": True
                }
                return data

            # ==========================================
            # Step 5: ì¿¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            # ==========================================
            query_terms = self.query_term_extractor.extract(user_prompt, parsed_query)


            # ==========================================
            # Step 6: AI ì ìˆ˜ ê³„ì‚°
            # ==========================================
            logger.info(f"[Step 5] AI ì ìˆ˜ ê³„ì‚°: {len(candidate_meetings)}ê°œ ëª¨ì„")

            intent = self.intent_detector.detect(user_prompt, enriched_query)

            scored_meetings = await self.scorer.score_meetings(
                user_id,
                user_context,
                candidate_meetings,
                enriched_query,
                intent,
                user_prompt=user_prompt,
                query_terms=query_terms
            )

            # Intent íƒœê¹…
            for m in scored_meetings:
                m["intent"] = intent

            # ==========================================
            # Step 7: ìƒìœ„ Nê°œ ì„ íƒ (query-hit ìš°ì„ )
            # ==========================================
            sorted_all = sorted(scored_meetings, key=lambda x: x["match_score"], reverse=True)

            # query-hit íŒì •
            def is_query_hit(rec: dict) -> bool:
                hay = f"{(rec.get('title') or '')} {(rec.get('subcategory') or '')} {(rec.get('category') or '')}".lower()
                for t in (query_terms or []):
                    if t and t.lower() in hay:
                        return True
                return False

            hits = [r for r in sorted_all if is_query_hit(r)]
            others = [r for r in sorted_all if not is_query_hit(r)]

            # ìµœì†Œ 2ê°œëŠ” hitë¡œ ì±„ì›€
            must = 2 if top_n >= 4 else 1
            picked = []

            picked.extend(hits[:must])
            picked.extend([r for r in others if r not in picked])

            top_recommendations = picked[:top_n]

            # ==========================================
            # Step 8: Reasoning ìƒì„±
            # ==========================================
            for rec in top_recommendations:
                if (not parsed_query.get("keywords")) or parsed_query.get("confidence", 0) < 0.6:
                    rec["reasoning"] = self.reasoning_generator.fallback_reasoning(rec, parsed_query)
                else:
                    rec["reasoning"] = await self.reasoning_generator.generate(
                        user_context, rec, parsed_query
                    )

            logger.info("ğŸ TOP=%s", [
                (r.get("meeting_id"), r.get("title"), r.get("category"), r.get("subcategory"))
                for r in top_recommendations
            ])

            # ==========================================
            # Step 9: ìµœì¢… ì‘ë‹µ
            # ==========================================
            return {
                "user_prompt": user_prompt,
                "parsed_query": parsed_query,
                "total_candidates": len(candidate_meetings),
                "recommendations": top_recommendations,
                "search_trace": {
                    "steps": trace_steps,
                    "final_level": trace_steps[-1]["level"] if trace_steps else 0,
                    "final_label": trace_steps[-1]["label"] if trace_steps else "L0 ì›ë³¸",
                    "fallback": False
                }
            }

        except Exception as e:
            logger.error(f"âŒ AI ì¶”ì²œ ì‹¤íŒ¨: {e}", exc_info=True)
            raise

    # ==========================================
    # Helper Methods
    # ==========================================

    async def _get_user_context(self, user_id: int) -> Dict:
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(f"{self.spring_boot_url}/api/users/{user_id}/context")
                response.raise_for_status()
                ctx = response.json()
                logger.info(f"âœ… ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì„±ê³µ: userId={user_id}")
                return ctx
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "user_id": user_id,
                "latitude": 37.5665,
                "longitude": 126.9780,
                "interests": "",
                "time_preference": "",
                "budget_type": "VALUE",
                "user_avg_rating": 0.0,
                "user_meeting_count": 0,
                "user_rating_std": 0.0
            }

    def _is_personal_emotion(self, user_prompt: str, parsed_query: dict) -> bool:
        """ê°œì¸ ê°ì • í‘œí˜„ ê°ì§€"""

        text = user_prompt.lower()
        conf = float(parsed_query.get("confidence", 0) or 0)

        # 1) ê°œì¸ ê°ì • í‚¤ì›Œë“œ ì²´í¬
        for category, keywords in self.PERSONAL_EMOTIONS.items():
            if any(kw in text for kw in keywords):
                # í™œë™ í‚¤ì›Œë“œê°€ í•¨ê»˜ ìˆìœ¼ë©´ OK
                activity_keywords = [
                    "ëª¨ì„", "ë§Œë‚˜", "ê°™ì´", "í•¨ê»˜", "í• ë˜", "í•˜ê³ ì‹¶",
                    "ì¶”ì²œ", "ì°¾ì•„", "í•´ì¤˜", "ìˆì„ê¹Œ"
                ]
                has_activity = any(ak in text for ak in activity_keywords)

                if not has_activity:
                    logger.info(f"[PERSONAL_EMOTION] {category} ê°ì§€: '{text}'")
                    return True

        # 2) ì‹ ì²´ ë¶€ìœ„ + í†µì¦ (í™œë™ ë¬´ê´€)
        body_pain = ["ì•„íŒŒ", "ì•„í”ˆ", "í†µì¦", "ì‘¤ì…”", "ì €ë ¤"]
        has_body_part = any(bp in text for bp in self.PERSONAL_EMOTIONS["body_part"])
        has_pain = any(p in text for p in body_pain)

        if has_body_part and has_pain:
            # "ë“±ì‚° í›„ ë°œê°€ë½ ì•„í””" ê°™ì€ ê±´ OK
            if "í›„" not in text and "ë•Œë¬¸" not in text:
                return True

        # 3) ë§¤ìš° ë‚®ì€ confidence + ì•„ë¬´ ì •ë³´ ì—†ìŒ (ì´ë¯¸ Step 2.6ì—ì„œ ì²˜ë¦¬ë¨)
        # ì¤‘ë³µ ì²´í¬ ë°©ì§€ë¥¼ ìœ„í•´ ì œê±°

        return False

    def _make_clarification_card(self, user_prompt: str, parsed_query: dict, user_context: dict) -> dict:
        """Clarification ì¹´ë“œ ìƒì„± (ê°œì„ )"""

        # ê°ì •ë³„ ë§ì¶¤ ë©”ì‹œì§€
        text = user_prompt.lower()

        if any(w in text for w in ["ì‚¬ë‘", "ì¢‹ì•„", "ì˜ˆë»", "ì´ë»"]):
            suggestion = "ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒê³¼ í•¨ê»˜ í•  í™œë™ì„ ë§í•´ì£¼ì„¸ìš”!"
            examples = [
                "ì˜ˆ: ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒì´ë‘ ì¹´í˜ ê°€ê¸°",
                "ì˜ˆ: ë°ì´íŠ¸ë¡œ ì „ì‹œíšŒ ë³´ê¸°",
                "ì˜ˆ: ì¹œêµ¬ë‘ ë§›ì§‘ íƒë°©",
            ]
        elif any(w in text for w in ["ë°œê°€ë½", "ì†ê°€ë½", "ë¬´ë¦"]):
            suggestion = "ì–´ë–¤ í™œë™ì„ í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
            examples = [
                "ì˜ˆ: ê°€ë²¼ìš´ ì‚°ì±…í•˜ê¸°",
                "ì˜ˆ: ì‹¤ë‚´ ìš”ê°€í•˜ê¸°",
                "ì˜ˆ: ì¹´í˜ì—ì„œ ì±… ì½ê¸°",
            ]
        else:
            suggestion = "ì–´ë–¤ ê±¸ í•˜ê³  ì‹¶ì€ì§€ í•œ ê°€ì§€ë§Œ ë” ì•Œë ¤ì¤˜ìš”!"
            examples = [
                "ì˜ˆ: ì§‘ ê·¼ì²˜ ì¹´í˜ì—ì„œ ë¸ŒëŸ°ì¹˜",
                "ì˜ˆ: ì‹¤ë‚´ì—ì„œ ë³´ë“œê²Œì„",
                "ì˜ˆ: ë°–ì—ì„œ ëŸ¬ë‹í•˜ê¸°",
            ]

        return {
            "meeting_id": -1,
            "title": f"{suggestion} ğŸ™‚",
            "category": "SYSTEM",
            "subcategory": "CLARIFY",
            "location_name": "ì¶”ì²œì„ ìœ„í•´ ì¢€ ë” êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•´ìš”",
            "image_url": None,
            "match_score": 0,
            "match_level": "INFO",
            "predicted_rating": None,
            "key_points": examples,
            "reasoning": (
                f"ì§€ê¸ˆ ì…ë ¥í•˜ì‹  '{user_prompt}'ë§Œìœ¼ë¡œëŠ” ì–´ë–¤ ëª¨ì„ì„ ì¶”ì²œí•´ì•¼ í• ì§€ "
                f"íŒë‹¨í•˜ê¸° ì–´ë ¤ì›Œìš”. {suggestion}"
            ),
            "is_clarification": True,
            "intent": "NEUTRAL",
        }