"""
AI Recommendation Integration Service
GPT íŒŒì‹± â†’ DB ê²€ìƒ‰ â†’ AI ëª¨ë¸ ì¶”ì²œ í†µí•©
"""

import httpx
import math
import uuid
from collections import Counter
from typing import List, Dict, Optional
import json
import re
import anyio
from typing import Set

import numpy as np

from app.core.scoring_utils import match_from_percentile
from app.services.gpt_prompt_service import GPTPromptService
from app.models.model_loader import model_loader
from app.core.logging import logger
from app.core.keyword_utils import clean_keywords


class AIRecommendationService:
    """AI ì¶”ì²œ í†µí•© ì„œë¹„ìŠ¤"""

    PROMPT_STOP = {"ëª¨ì„", "ìŠ¤í„°ë””", "ì¶”ì²œ", "í•´ì¤˜", "í•´ì£¼ì„¸ìš”", "ê°™ì´", "í• ë§Œí•œ", "í• ", "í•˜ëŠ”", "ì›í•´", "ì‹¶ì–´"}
    PROMPT_STOP |= {"í• ìˆ˜ìˆëŠ”", "í• ìˆ˜ìˆ", "ê°€ëŠ¥í•œ", "ê°€ëŠ¥", "í•´ë³¼ë§Œí•œ", "í• ë§Œí•œê±°", "ë§Œí•œê±°", "ê±°", "ê²ƒ"}

    SYN_MAP = {
        # ìŠ¤í„°ë”” ê³„ì—´
        "ì˜ì–´íšŒí™”": ["ì˜ì–´", "íšŒí™”", "ìŠ¤í”¼í‚¹"],
        "ì˜ì–´": ["ì˜ì–´", "íšŒí™”", "ìŠ¤í”¼í‚¹"],
        "íšŒí™”": ["íšŒí™”", "ìŠ¤í”¼í‚¹"],
        "í† ìµ": ["í† ìµ"],
        "ì˜¤í”½": ["ì˜¤í”½"],
        "ì½”ë”©": ["ì½”ë”©", "ê°œë°œ", "í”„ë¡œê·¸ë˜ë°"],
        "ê°œë°œ": ["ê°œë°œ", "ì½”ë”©", "í”„ë¡œê·¸ë˜ë°"],
        "í”„ë¡œê·¸ë˜ë°": ["í”„ë¡œê·¸ë˜ë°", "ì½”ë”©", "ê°œë°œ"],
        "ì¶¤": ["ì¶¤", "ëŒ„ìŠ¤", "dance", "kpop", "ì¼€ì´íŒ", "ë°©ì†¡ëŒ„ìŠ¤"],
        "ëŒ„ìŠ¤": ["ëŒ„ìŠ¤", "ì¶¤", "kpop", "ì¼€ì´íŒ", "ë°©ì†¡ëŒ„ìŠ¤"],

        "ë¶“ê¸€ì”¨": ["ë¶“ê¸€ì”¨", "ìº˜ë¦¬", "ìº˜ë¦¬ê·¸ë¼í”¼", "ì„œì˜ˆ"],
        "ìº˜ë¦¬ê·¸ë¼í”¼": ["ìº˜ë¦¬ê·¸ë¼í”¼", "ìº˜ë¦¬", "ë¶“ê¸€ì”¨", "ì„œì˜ˆ"],

        "ì†ìœ¼ë¡œ": ["ê³µë°©", "ë§Œë“¤ê¸°", "diy", "ìº˜ë¦¬ê·¸ë¼í”¼", "ê·¸ë¦¼", "ë„ì˜ˆ", "ê°€ì£½ê³µì˜ˆ"],
        "diy": ["diy", "ê³µë°©", "ë§Œë“¤ê¸°", "ë„ì˜ˆ", "ê°€ì£½ê³µì˜ˆ", "ìº˜ë¦¬ê·¸ë¼í”¼"],
    }

    SYN_MAP.update({
        "ê³µë†€ì´": ["ì¶•êµ¬", "í’‹ì‚´", "ë†êµ¬", "ë°°êµ¬", "ë°°ë“œë¯¼í„´", "í…Œë‹ˆìŠ¤"],
        "ë¨¸ë¦¬": ["ë³´ë“œê²Œì„", "ë°©íƒˆì¶œ", "ì²´ìŠ¤", "í¼ì¦", "ì¶”ë¦¬"],
        "ë¨¸ë¦¬ì“°": ["ë³´ë“œê²Œì„", "ë°©íƒˆì¶œ", "ì²´ìŠ¤", "í¼ì¦", "ì¶”ë¦¬"],
        "ë‘ë‡Œ": ["ë³´ë“œê²Œì„", "ë°©íƒˆì¶œ", "ì²´ìŠ¤", "í¼ì¦", "ì¶”ë¦¬"],
        "ì¶”ë¦¬": ["ë°©íƒˆì¶œ", "ì¶”ë¦¬", "ë¯¸ìŠ¤í„°ë¦¬", "ë³´ë“œê²Œì„"],
        "ì „ëµ": ["ë³´ë“œê²Œì„", "ì²´ìŠ¤", "ì „ëµ"],
    })

    SYN_MAP.update({
        "ì‚¬ì§„": ["ì‚¬ì§„", "ì´¬ì˜", "í¬í† ", "ì¹´ë©”ë¼", "ìŠ¤ëƒ…", "í•„ì¹´"],
        "í¬í† ": ["ì‚¬ì§„", "ì´¬ì˜", "í¬í† ", "ì¹´ë©”ë¼", "ìŠ¤ëƒ…", "í•„ì¹´"],
        "ì´¬ì˜": ["ì‚¬ì§„", "ì´¬ì˜", "í¬í† ", "ì¹´ë©”ë¼", "ìŠ¤ëƒ…", "í•„ì¹´"],
    })

    def __init__(
        self,
        gpt_service: GPTPromptService,
        spring_boot_url: str = "http://localhost:8080"
    ):
        self.gpt_service = gpt_service
        self.spring_boot_url = spring_boot_url

    # -------------------------
    # Normalizers (Spring Enum/DB ê°’ í˜¸í™˜)
    # -------------------------
    def _normalize_timeslot(self, ts: Optional[str]) -> Optional[str]:
        """Spring Enum: MORNING/AFTERNOON/EVENING/NIGHT"""
        if not ts:
            return None

        raw = str(ts).strip()

        # âœ… "MORNING,FLEXIBLE" ê°™ì€ ê°’ ë“¤ì–´ì˜¤ë©´ ì²« í† í°ë§Œ ì‚¬ìš©
        if "," in raw:
            raw = raw.split(",")[0].strip()

        lower = raw.lower()
        mapping = {
            "morning": "MORNING",
            "afternoon": "AFTERNOON",
            "evening": "EVENING",
            "night": "NIGHT",
            "ì˜¤ì „": "MORNING",
            "ì•„ì¹¨": "MORNING",
            "ì ì‹¬": "AFTERNOON",
            "ì˜¤í›„": "AFTERNOON",
            "ì €ë…": "EVENING",
            "ë°¤": "NIGHT",
            "ì•¼ê°„": "NIGHT",
        }
        return mapping.get(lower, raw.upper())

    def _normalize_vibe(self, v: Optional[str]) -> Optional[str]:
        if not v:
            return None
        raw = str(v).strip().lower()

        mapping = {
            "ì‹ ë‚˜ëŠ”": "ì¦ê±°ìš´",
            "ì¬ë°ŒëŠ”": "ì¦ê±°ìš´",
            "ì¦ê±°ìš´": "ì¦ê±°ìš´",
            "í™œê¸°ì°¬": "í™œê¸°ì°¬",
            "ì—ë„ˆì§€": "í™œê¸°ì°¬",
            "ì—ë„ˆì§€ë„˜ì¹˜ëŠ”": "í™œê¸°ì°¬",

            "í¸ì•ˆí•œ": "ì—¬ìœ ë¡œìš´",
            "ì—¬ìœ ë¡œìš´": "ì—¬ìœ ë¡œìš´",
            "íë§": "íë§",
            "ì°¨ë¶„í•œ": "ì—¬ìœ ë¡œìš´",
            "ì¡°ìš©í•œ": "ì—¬ìœ ë¡œìš´",
            "ê°ì„±": "ê°ì„±ì ì¸",
            "ê°ì„±ì ì¸": "ê°ì„±ì ì¸",

            "ë°°ì›€": "ë°°ì›€",
            "ì§„ì§€í•œ": "ì§„ì§€í•œ",
            "ê±´ê°•í•œ": "ê±´ê°•í•œ",
        }

        # ë¶€ë¶„ í¬í•¨ë„ ì»¤ë²„
        for k, vv in mapping.items():
            if k in raw:
                return vv
        return v

    def _normalize_location_type(self, lt: Optional[str]) -> Optional[str]:
        """Spring Enum: INDOOR/OUTDOOR"""
        if not lt:
            return None
        raw = str(lt).strip()
        lower = raw.lower()
        mapping = {
            "indoor": "INDOOR",
            "outdoor": "OUTDOOR",
            "ì‹¤ë‚´": "INDOOR",
            "ì‹¤ì™¸": "OUTDOOR",
            "ì•¼ì™¸": "OUTDOOR",
        }
        return mapping.get(lower, raw.upper())

    def _normalize_budget_for_model(self, bt: Optional[str]) -> str:
        """ëª¨ë¸ ì…ë ¥ì€ ì†Œë¬¸ìë¡œ í†µì¼ (value/quality)"""
        if not bt:
            return "value"
        raw = str(bt).strip()
        mapping = {
            "VALUE": "value", "value": "value", "ê°€ì„±ë¹„": "value", "í•©ë¦¬": "value",
            "QUALITY": "quality", "quality": "quality", "í’ˆì§ˆ": "quality",
        }
        return mapping.get(raw, mapping.get(raw.upper(), mapping.get(raw.lower(), "value")))

    def _normalize_term(self, t: str) -> str:
        t = t.strip().lower()
        t = re.sub(r"(ê´€ë ¨(ëœ|í•œ)?|ìœ„ì£¼|ì¤‘ì‹¬|ëŠë‚Œ|ê°™ì€)$", "", t)  # âœ… ì¶”ê°€
        t = re.sub(r"(ì—ì„œ|ìœ¼ë¡œ|ë¡œ|ë§ê³ |ë¹¼ê³ |ì œì™¸)$", "", t)
        # âœ… 2) í•œ ê¸€ì ì¡°ì‚¬(ì´/ê°€/ì€/ëŠ”/ì„/ë¥¼)ëŠ” 'ë‹¨ë… í† í°'ì—ì„œëŠ” ì œê±°í•˜ì§€ ì•ŠìŒ
        # (ê³µë†€ì´ ê°™ì€ ë‹¨ì–´ê°€ ê¹¨ì§ ë°©ì§€)
        # í•„ìš”í•˜ë©´ "ê³µ ë†€ì´"ì²˜ëŸ¼ ë„ì–´ì“°ê¸° ëœ ì¼€ì´ìŠ¤ì—ì„œë§Œ ì²˜ë¦¬í•˜ë„ë¡,
        # ìƒìœ„ì—ì„œ ë¬¸ì¥ ì „ì²´ì— ëŒ€í•´ ê³µë°± ê¸°ë°˜ ì²˜ë¦¬í•  ë•Œë§Œ ì ìš©í•˜ëŠ” ê²Œ ì•ˆì „í•¨.

        return t

    # -------------------------
    # Intent (ë¬¸ì¥ ì˜ë„)
    # -------------------------
    def _detect_intent(self, user_prompt: str, parsed_query: dict) -> str:
        t = (user_prompt or "").lower()

        # âœ… 1ìˆœìœ„: ê²©ë ¬í•¨ í‚¤ì›Œë“œ (ìµœìš°ì„ !)
        intense_keywords = ["ê²©ì •", "ê²©ë ¬", "ì—´ì •", "ê°•ë ¬", "ìµìŠ¤íŠ¸ë¦¼", "í•˜ë“œ"]
        if any(k in t for k in intense_keywords):
            return "ACTIVE"

        brain_words = ["ë¨¸ë¦¬", "ë¨¸ë¦¬ì“°", "ë‘ë‡Œ", "ì¶”ë¦¬", "ì „ëµ", "í¼ì¦", "í€´ì¦ˆ", "ë°©íƒˆì¶œ", "ë³´ë“œê²Œì„", "ì²´ìŠ¤"]
        if any(w in t for w in brain_words):
            return "BRAIN"

        vibe = parsed_query.get("vibe", "")
        if vibe in ["ê²©ë ¬í•œ", "í™œê¸°ì°¬", "ì—ë„ˆì§€", "ì¦ê±°ìš´"]:
            return "ACTIVE"  # ë˜ëŠ” "FUN" ìƒˆë¡œ ë§Œë“¤ì–´ë„ ë¨

        # âœ… 2ìˆœìœ„: vibe í‚¤ì›Œë“œ
        quiet_words = ["ì¡°ìš©", "ì‰¬", "íë§", "í¸í•˜ê²Œ", "ì—¬ìœ ", "ì°¨ë¶„", "í¸ì•ˆ"]
        active_words = ["ëŸ¬ë‹", "ìš´ë™", "ë›°", "ë°°ë“œë¯¼í„´", "ì¶•êµ¬", "í´ë¼ì´ë°"]
        hands_words = ["ì†ìœ¼ë¡œ", "ê³µë°©", "diy", "ë§Œë“¤ê¸°", "ìˆ˜ê³µì˜ˆ", "ìº˜ë¦¬", "ë¶“ê¸€ì”¨", "ê·¸ë¦¼", "ë„ì˜ˆ"]
        if any(w in t for w in hands_words):
            return "HANDS_ON"

        vibe = parsed_query.get("vibe", "")

        # âœ… vibe="ê²©ë ¬í•œ" ë¬´ì¡°ê±´ ACTIVE
        if vibe in ["ê²©ë ¬í•œ", "í™œê¸°ì°¬", "ì—ë„ˆì§€"]:
            return "ACTIVE"

        if any(w in t for w in quiet_words) or vibe in ["í¸ì•ˆí•œ", "ì—¬ìœ ë¡œìš´", "ì¡°ìš©í•œ"]:
            return "QUIET"

        if any(w in t for w in active_words):
            return "ACTIVE"

        return "NEUTRAL"

    # -------------------------
    # Search payload builder (ì¤‘ìš”)
    # -------------------------
    def _should_apply_time_slot(self, q: dict) -> bool:
        # time_slotì€ ì¶”ì¸¡ì´ ì„ì´ë¯€ë¡œ confidence ë†’ì„ ë•Œë§Œ í•„í„°ë¡œ ì‚¬ìš©
        return q.get("time_slot") is not None and q.get("confidence", 0) >= 0.9

    def _should_apply_vibe(self, q: dict) -> bool:
        return q.get("vibe") is not None and q.get("confidence", 0) >= 0.9

    def _infer_location_type(self, q: dict) -> Optional[str]:
        kws = q.get("keywords") or []
        text = " ".join(kws)
        if "ì‹¤ë‚´" in text:
            return "INDOOR"
        if "ì•¼ì™¸" in text or "ì‹¤ì™¸" in text:
            return "OUTDOOR"
        return None

    def _to_spring_search_request(self, enriched_query: dict, user_ctx: dict, user_prompt: str = "") -> dict:
        raw_keywords = enriched_query.get("keywords") or []

        # âœ… 1) í•œ ë²ˆë§Œ ì •ì œ (ë„ˆê°€ ë§Œë“  clean_keywords ì‚¬ìš©)
        keywords = clean_keywords(raw_keywords)

        # âœ… 2) categoryì™€ ì¤‘ë³µ ì œê±° (ì •ì œëœ keywordsì—ì„œ ì œê±°í•´ì•¼ í•¨)
        category = enriched_query.get("category")
        if category:
            keywords = [k for k in keywords if str(k).strip().lower() != str(category).strip().lower()]

        logger.info("[PAYLOAD_KEYWORDS] raw=%s -> cleaned=%s", raw_keywords, keywords)

        # âœ… ìœ ì € ì¢Œí‘œ
        lat = user_ctx.get("lat") or user_ctx.get("latitude")
        lng = user_ctx.get("lng") or user_ctx.get("longitude")

        # âœ… locationQuery
        location_query = enriched_query.get("location_query") or enriched_query.get("locationQuery")

        # âœ… "ê·¼ì²˜/ì£¼ë³€/ì§‘" ì˜ë„
        near_me = self._is_near_me_phrase(location_query) or self._is_near_me_phrase(user_prompt)  # âœ… user_promptë„ ì²´í¬

        # âœ… timeSlot: "ìœ ì € ì„ í˜¸" ì ˆëŒ€ ì„ì´ì§€ ì•Šê²Œ!
        conf = float(enriched_query.get("confidence", 0) or 0)
        # âœ… í•´ê²°: "ì•„ì¹¨/ì ì‹¬/ì €ë…" ê°™ì€ ëª…í™•í•œ ì‹œê°„ í‘œí˜„ì€ conf ë‚®ì•„ë„ í•„í„° ì ìš©
        gpt_ts = enriched_query.get("time_slot")

        # conf 0.6 ì´ìƒì´ê³  time_slotì´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ í•„í„°ë§
        explicit_ts = self._has_explicit_timeslot(user_prompt)
        time_slot = self._normalize_timeslot(gpt_ts) if (gpt_ts and (conf >= 0.6 or explicit_ts)) else None

        # âœ… locationType: GPTê°€ íŒŒì‹±í•œ ê²ƒë§Œ ì‚¬ìš© (ìœ ì € ì„ í˜¸ ì„ì§€ ì•Šê¸°!)
        gpt_location_type = enriched_query.get("location_type")
        location_type = self._normalize_location_type(gpt_location_type) if gpt_location_type else None

        payload = {
            "category": enriched_query.get("category"),
            "subcategory": enriched_query.get("subcategory"),

            # âœ… GPT time_slotë§Œ, conf ë†’ì„ ë•Œë§Œ
            "timeSlot": time_slot,

            # âœ… locationType ì¶”ê°€ - Springì—ì„œ í•„í„°ë§
            "locationType": location_type,

            "keywords": keywords if keywords else None,   # âœ… ì—¬ê¸°! ì—†ìœ¼ë©´ None

            # âœ… userLocationì€ í•­ìƒ ë³´ë‚´ë„ ë¨ (ê±°ë¦¬ ê³„ì‚°ìš©)
            "userLocation": {
                "latitude": lat,
                "longitude": lng
            },

            "locationQuery": location_query,
            "maxCost": enriched_query.get("maxCost") or enriched_query.get("max_cost"),
        }


        logger.info(f"[PAYLOAD_DEBUG] category={payload.get('category')} subcategory={payload.get('subcategory')}")

        # âœ… radiusëŠ” "ê·¼ì²˜ ì˜ë„ì¼ ë•Œë§Œ" í¬í•¨
        if near_me:
            payload["radius"] = float(enriched_query.get("radius") or 10.0)

        # ë¡œê·¸
        logger.info(
            f"[PAYLOAD] near_me={near_me} locationType={location_type} "
            f"userLocation={payload.get('userLocation')} "
            f"radius={payload.get('radius', None)} timeSlot={payload.get('timeSlot')}"
        )
        logger.info(f"[PAYLOAD_KEYWORDS] raw={raw_keywords} -> cleaned={keywords}")

        # null/""/[] ì œê±°
        def clean(o):
            if isinstance(o, dict):
                return {k: clean(v) for k, v in o.items() if v is not None and v != "" and v != []}
            return o

        return clean(payload)

    # -------------------------
    # Step 4: candidate search + relaxation
    # -------------------------
    async def _search_meetings(self, enriched_query: dict, user_context: dict, user_prompt: str = "") -> list[dict]:
        try:
            payload = self._to_spring_search_request(enriched_query, user_context, user_prompt)
            logger.info(f"[PAYLOAD_FULL] {payload}")

            logger.info(f"[SEARCH_REQUEST] URL={self.spring_boot_url}/api/meetings/search")
            logger.info(f"[SEARCH_PAYLOAD] {json.dumps(payload, ensure_ascii=False)}")  # â† import json í•„ìš”

            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.post(
                    f"{self.spring_boot_url}/api/meetings/search",
                    json=payload
                )

            logger.info(f"[SEARCH_RESPONSE] status={response.status_code}")

            if response.status_code == 200:
                result = response.json()
                meetings = result.get("meetings", [])

                # âœ… ì¶”ê°€: Spring ì‘ë‹µ í™•ì¸
                logger.info(f"ğŸ“¦ Spring ì‘ë‹µ: {len(meetings)}ê°œ ëª¨ì„ ë°›ìŒ")
                if meetings:
                    ids = [m.get('meeting_id') or m.get('meetingId') for m in meetings[:5]]
                    logger.info(f"ğŸ” ìƒìœ„ 5ê°œ ID: {ids}")

                return meetings
            else:
                logger.warning(f"âš ï¸ ëª¨ì„ ê²€ìƒ‰ ì‹¤íŒ¨: {response.status_code} body={response.text}")
                return []
        except Exception as e:
            logger.error(f"âš ï¸ ëª¨ì„ ê²€ìƒ‰ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return []


    async def _search_with_relaxation(self, base_query: dict, user_context: dict, trace_steps: list,
                                      user_prompt: str = "") -> list[dict]:
        """
        - confidence ê¸°ë°˜ ì´ˆê¸° í•„í„° ê°•ë„ ì¡°ì ˆ
        - relax ìš°ì„ ìˆœìœ„: locationQuery -> vibe -> timeSlot -> keywords -> subcategory -> (ë§ˆì§€ë§‰) category
        - category ê°€ë“œ: categoryê°€ ìˆì—ˆëŠ”ë° ê²°ê³¼ê°€ ì „ë¶€ ë‹¤ë¥¸ categoryë©´ locationQuery ì œê±° í›„ category ê³ ì • ì¬ì‹œë„
        - trace_steps ìœ ì§€
        """

        conf = float(base_query.get("confidence", 0) or 0)
        explicit_quiet = self._has_explicit_quiet(user_prompt)
        explicit_loc = self._has_explicit_location(user_prompt, base_query)
        logger.info(f"[RELAX_FLAGS] explicit_loc={explicit_loc} explicit_quiet={explicit_quiet}")

        # âœ… ì‹œì‘ ë¡œê·¸
        logger.info(f"ğŸ”¥ [RELAX_START] conf={conf:.2f}, base_query={base_query}")

        def drop_keys(q: dict, *keys):
            qq = dict(q)
            for k in keys:
                qq.pop(k, None)
            return qq

        def norm(q: dict):
            return dict(q)  # ì•„ë¬´ê²ƒë„ ë°”ê¾¸ì§€ ì•Šê¸°

        # AIRecommendationService.pyì˜ _search_with_relaxation() ìˆ˜ì •

        async def _try(label: str, q: dict, level: int):
            q = norm(q)

            logger.info(f"ğŸ”¥ [RELAX_{level}] {label} ì‹œì‘")
            logger.info(f"ğŸ”¥ [RELAX_{level}] query={q}")

            meetings = await self._search_meetings(q, user_context, user_prompt)
            meetings = meetings or []

            # âœ… locationType 2ì°¨ í•„í„° (Spring í†µê³¼í•œ ê²ƒ ì¬í™•ì¸)  --- ê°œì„ ë²„ì „
            requested_type = q.get("location_type")
            if requested_type:
                requested_normalized = self._normalize_location_type(requested_type)
                before_count = len(meetings)

                meetings = [
                    m for m in meetings
                    if self._normalize_location_type(self._pick_location_type_from_raw(m)) == requested_normalized
                ]

                if len(meetings) < before_count:
                    logger.info(
                        f"ğŸ” [RELAX_{level}] locationType 2ì°¨ í•„í„°(raw): {requested_normalized} | "
                        f"{before_count} -> {len(meetings)}"
                    )

            logger.info(f"ğŸ”¥ [RELAX_{level}] {label} ì™„ë£Œ: {len(meetings)}ê°œ ë°›ìŒ")

            trace_steps.append({
                "level": level,
                "label": label,
                "payload": self._to_spring_search_request(q, user_context, user_prompt),
                "count": len(meetings),
                "cats": dict(Counter((m.get("category"), m.get("subcategory")) for m in meetings)) if meetings else {},
            })
            return meetings

        base_cat = (base_query.get("category") or "").strip() or None

        # -----------------------
        # 1) conf ê¸°ë°˜ ì‹œì‘ ì¿¼ë¦¬ ì •ê·œí™”
        # -----------------------
        # conf ê¸°ë°˜ ì‹œì‘ ì¿¼ë¦¬ ì •ê·œí™”
        q0 = dict(base_query)

        if conf < 0.70:
            q0 = drop_keys(q0, "subcategory")

        # time_slotì€ conf ë‚®ìœ¼ë©´ ì œê±° (vibeë‘ ë¶„ë¦¬!)
        if conf < 0.85:
            q0 = drop_keys(q0, "time_slot", "timeSlot")

        # vibeëŠ” explicit_quiet ì•„ë‹ ë•Œë§Œ ì œê±°
        if conf < 0.85 and not explicit_quiet:
            q0 = drop_keys(q0, "vibe")

        # âœ… L0
        cands = await _try("L0(conf ë°˜ì˜)", q0, 0)

        if cands:
            requested_sub = (base_query.get("subcategory") or "").strip()

            # âœ… subcategory ìš°ì„  í•„í„° (ì‹¤ì œ ë™ì‘ ë²„ì „)
            if requested_sub:
                before = len(cands)
                cands_sub = [
                    m for m in cands
                    if (m.get("subcategory") or "").strip() == requested_sub
                ]
                if cands_sub:
                    logger.info(
                        f"[RELAX_0] subcategory ìš°ì„ í•„í„° {before}->{len(cands_sub)} ({requested_sub})"
                    )
                    return cands_sub

            if base_cat and all((m.get("category") or "").strip() != base_cat for m in cands):
                # âœ… 1ì°¨: location_query ì œê±° (ê¸°ì¡´)
                q_fix = drop_keys(q0, "location_query", "locationQuery")
                c2 = await _try("L0-guard(locationQuery ì œê±°)", q_fix, 1)
                if c2 and any((m.get("category") or "").strip() == base_cat for m in c2):
                    return c2

                # âœ… 2ì°¨: location_typeê¹Œì§€ ì œê±°í•´ì„œ category ì‚´ë¦¬ê¸°
                q_fix2 = drop_keys(q0, "location_type", "locationType", "location_query", "locationQuery")
                c3 = await _try("L0-guard(locationType ì œê±°, category ìœ ì§€)", q_fix2, 2)
                if c3:
                    return c3

            return cands

        # -----------------------
        # 2) relax plan
        # -----------------------
        if conf >= 0.90:
            if explicit_loc:
                # âœ… ì¥ì†Œê°€ ëª…ì‹œëœ ê²½ìš°: locationQueryëŠ” ìµœëŒ€í•œ ìœ ì§€í•˜ê³  ë‹¤ë¥¸ ê²ƒë¶€í„° ëº€ë‹¤
                plans = [
                    ("L1 vibe ì œê±°", ("vibe",)),
                    ("L2 timeSlot ì œê±°", ("time_slot", "timeSlot")),
                    ("L3 subcategory ì œê±°", ("subcategory",)),
                    ("L4 keywords ì œê±°", ("keywords",)),
                    ("L5 locationQuery ì œê±°", ("location_query", "locationQuery")),  # âœ… ë’¤ë¡œ
                    ("L6 category ì œê±°", ("category",)),
                ]
            else:
                plans = [
                    ("L1 locationQuery ì œê±°", ("location_query", "locationQuery")),
                    ("L2 vibe ì œê±°", ("vibe",)),
                    ("L3 timeSlot ì œê±°", ("time_slot", "timeSlot")),
                    ("L4 subcategory ì œê±°", ("subcategory",)),
                    ("L5 keywords ì œê±°", ("keywords",)),
                    ("L6 category ì œê±°", ("category",)),
                ]
        elif conf >= 0.75:
            if explicit_loc:
                plans = [
                    ("L1 subcategory ì œê±°", ("subcategory",)),
                    ("L2 keywords ì œê±°", ("keywords", "keyword")),
                    ("L3 locationQuery ì œê±°", ("location_query", "locationQuery")),  # âœ… ë’¤ë¡œ
                    ("L4 category ì œê±°", ("category",)),
                ]
            else:
                plans = [
                    ("L1 locationQuery ì œê±°", ("location_query", "locationQuery")),
                    ("L2 subcategory ì œê±°", ("subcategory",)),
                    ("L3 keywords ì œê±°", ("keywords", "keyword")),
                    ("L4 category ì œê±°", ("category",)),
                ]
        else:
            if explicit_loc:
                plans = [
                    ("L1 keywords ì œê±°", ("keywords", "keyword")),
                    ("L2 subcategory ì œê±°", ("subcategory",)),
                    ("L3 locationQuery ì œê±°", ("location_query", "locationQuery")),  # âœ… ë’¤ë¡œ
                    ("L4 category ì œê±°", ("category",)),
                ]
            else:
                plans = [
                    ("L1 locationQuery ì œê±°", ("location_query", "locationQuery")),
                    ("L2 keywords ì œê±°", ("keywords", "keyword")),
                    ("L3 subcategory ì œê±°", ("subcategory",)),
                    ("L4 category ì œê±°", ("category",)),
                ]
        # -----------------------
        # 3) relax ìˆœì°¨ ìˆ˜í–‰
        # -----------------------
        current = dict(q0)
        level = 1
        for label, keys in plans:
            qn = drop_keys(current, *keys)
            cands = await _try(label, qn, level)

            if cands:
                # category ê°€ë“œ
                if base_cat and all((m.get("category") or "").strip() != base_cat for m in cands):
                    q_fix = drop_keys(qn, "location_query", "locationQuery")
                    c2 = await _try(f"{label}-guard(location ì œê±°, category ìœ ì§€)", q_fix, level + 1)
                    if c2:
                        return c2
                return cands

            current = qn
            level += 1

        logger.warning("ğŸ”¥ [RELAX_END] ëª¨ë“  ë‹¨ê³„ ì‹¤íŒ¨ - ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜")
        return []

    def _normalize_query_taxonomy(self, q: dict) -> dict:
        """
        ë„ˆí¬ DB ì¹´í…Œê³ ë¦¬ ì²´ê³„ ê¸°ì¤€ìœ¼ë¡œ category/subcategory êµì •.
        categories = ['ìŠ¤í¬ì¸ ','ë§›ì§‘','ì¹´í˜','ë¬¸í™”ì˜ˆìˆ ','ìŠ¤í„°ë””','ì·¨ë¯¸í™œë™','ì†Œì…œ']
        """
        VALID_CATS = {"ìŠ¤í¬ì¸ ", "ë§›ì§‘", "ì¹´í˜", "ë¬¸í™”ì˜ˆìˆ ", "ìŠ¤í„°ë””", "ì·¨ë¯¸í™œë™", "ì†Œì…œ"}

        SUB_TO_CAT = {
            # ìŠ¤í¬ì¸ 
            "ëŸ¬ë‹": "ìŠ¤í¬ì¸ ", "ì¶•êµ¬": "ìŠ¤í¬ì¸ ", "ë°°ë“œë¯¼í„´": "ìŠ¤í¬ì¸ ", "ë“±ì‚°": "ìŠ¤í¬ì¸ ",
            "ìš”ê°€": "ìŠ¤í¬ì¸ ", "ì‚¬ì´í´ë§": "ìŠ¤í¬ì¸ ", "í´ë¼ì´ë°": "ìŠ¤í¬ì¸ ",

            # ë§›ì§‘
            "í•œì‹": "ë§›ì§‘", "ì¤‘ì‹": "ë§›ì§‘", "ì¼ì‹": "ë§›ì§‘", "ì–‘ì‹": "ë§›ì§‘",
            "ì´ìì¹´ì•¼": "ë§›ì§‘", "íŒŒì¸ë‹¤ì´ë‹": "ë§›ì§‘",

            # ì¹´í˜
            "ì¹´í˜íˆ¬ì–´": "ì¹´í˜", "ë¸ŒëŸ°ì¹˜": "ì¹´í˜", "ë””ì €íŠ¸": "ì¹´í˜", "ë² ì´ì»¤ë¦¬": "ì¹´í˜", "í‹°í•˜ìš°ìŠ¤": "ì¹´í˜",

            # ë¬¸í™”ì˜ˆìˆ 
            "ì „ì‹œíšŒ": "ë¬¸í™”ì˜ˆìˆ ", "ê³µì—°": "ë¬¸í™”ì˜ˆìˆ ", "ê°¤ëŸ¬ë¦¬": "ë¬¸í™”ì˜ˆìˆ ", "ê³µë°©ì²´í—˜": "ë¬¸í™”ì˜ˆìˆ ",
            "ì‚¬ì§„ì´¬ì˜": "ë¬¸í™”ì˜ˆìˆ ", "ë²„ìŠ¤í‚¹": "ë¬¸í™”ì˜ˆìˆ ",

            # ìŠ¤í„°ë””
            "ì˜ì–´íšŒí™”": "ìŠ¤í„°ë””", "ë…ì„œí† ë¡ ": "ìŠ¤í„°ë””", "ì½”ë”©": "ìŠ¤í„°ë””",
            "ì¬í…Œí¬": "ìŠ¤í„°ë””", "ìê²©ì¦": "ìŠ¤í„°ë””", "ì„¸ë¯¸ë‚˜": "ìŠ¤í„°ë””",

            # ì·¨ë¯¸í™œë™
            "ê·¸ë¦¼": "ì·¨ë¯¸í™œë™", "ë² ì´í‚¹": "ì·¨ë¯¸í™œë™", "ì¿ í‚¹": "ì·¨ë¯¸í™œë™",
            "í”Œë¼ì›Œ": "ì·¨ë¯¸í™œë™", "ìº˜ë¦¬ê·¸ë¼í”¼": "ì·¨ë¯¸í™œë™", "ëŒ„ìŠ¤": "ì·¨ë¯¸í™œë™",

            # ì†Œì…œ
            "ë³´ë“œê²Œì„": "ì†Œì…œ", "ë°©íƒˆì¶œ": "ì†Œì…œ", "ë³¼ë§": "ì†Œì…œ",
            "ë‹¹êµ¬": "ì†Œì…œ", "ë…¸ë˜ë°©": "ì†Œì…œ", "ì™€ì¸ë°”": "ì†Œì…œ",
        }

        qq = dict(q)

        cat = (qq.get("category") or "").strip()
        sub = (qq.get("subcategory") or "").strip()

        # 1) subcategoryê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ìµœìš°ì„ ìœ¼ë¡œ category êµì •
        if sub:
            mapped = SUB_TO_CAT.get(sub)
            if mapped:
                qq["category"] = mapped
            else:
                qq.pop("subcategory", None)  # categoryëŠ” ìœ ì§€

        # 2) category ìœ íš¨ì„± ì²´í¬
        cat2 = (qq.get("category") or "").strip()
        if cat2 and cat2 not in VALID_CATS:
            # ì´ìƒí•œ category(ì˜ˆ: 'ì†Œì…œ'ë¡œ ì˜ëª» ì°íŒ 'ìŠ¤í¬ì¸ ' ë“±) ë“¤ì–´ì˜¤ë©´ ì œê±°
            qq.pop("category", None)

        return qq

    def _extract_query_terms(self, user_prompt: str, parsed_query: dict) -> list[str]:
        p = (user_prompt or "").strip().lower()
        if not p:
            return []

        # âœ… query_termsì— ë„£ìœ¼ë©´ ì˜¤íˆë ¤ ë­í‚¹ì„ ë§ì¹˜ëŠ” 'ë©”íƒ€ ë‹¨ì–´' (hit=0 â†’ -12 íŒ¨ë„í‹° ë°©ì§€)
        QUERY_TERM_STOP: Set[str] = {
            "ì‹¤ë‚´", "ì‹¤ì™¸", "ì•¼ì™¸", "ë°–", "ì¸ë„ì–´", "ì•„ì›ƒë„ì–´",
            "ì¦ê²ê²Œ", "ì¦ê±°ìš´", "ì¬ë°Œê²Œ", "ì¬ë°ŒëŠ”", "ì‹ ë‚˜ê²Œ", "ì‹ ë‚˜ëŠ”",
            "í¸í•˜ê²Œ", "í¸ì•ˆí•˜ê²Œ", "ì—¬ìœ ë¡­ê²Œ", "ì¡°ìš©íˆ", "íë§", "ì°¨ë¶„í•˜ê²Œ",
            "ê°€ë³ê²Œ", "ì ë‹¹íˆ", "ê·¸ëƒ¥", "ì•„ë¬´ê±°ë‚˜", "ì¶”ì²œ",
         }

        terms = []

        # âœ… (ì¶”ê°€) ë¶™ì–´ì¨ë„ ì¡íˆëŠ” íŠ¸ë¦¬ê±°
        TRIGGERS = ["ì‚¬ì§„", "ì´¬ì˜", "í¬í† ", "ì¹´ë©”ë¼", "í•„ì¹´", "ìŠ¤ëƒ…"]
        for t in TRIGGERS:
            if t in p and t not in terms:
                terms.append(t)

        # âœ… 1) SYN_MAP ìŠ¤ìº”: keyê°€ ë¬¸ì¥ì— í¬í•¨ë˜ë©´ terms í™•ì¥
        for k, syns in self.SYN_MAP.items():
            if k in p:
                for t in syns:
                    t2 = str(t).strip().lower()
                    if t2 and t2 not in QUERY_TERM_STOP and t2 not in terms:
                        terms.append(t2)

        # âœ… 2) ê·¸ë˜ë„ ë¹„ì—ˆìœ¼ë©´ ê¸°ì¡´ í† í¬ë‚˜ì´ì§• fallback
        if not terms:
            toks = re.split(r"[\s,./!?()\-]+", p)
            toks = [self._normalize_term(t) for t in toks]
            toks = [t for t in toks if t and t not in self.PROMPT_STOP and len(t) >= 2]
            for t in toks:
                if t in QUERY_TERM_STOP:
                    continue
                if t not in terms:
                    terms.append(t)

        # ë§ˆì§€ë§‰ í•œ ë²ˆ ë” ì•ˆì „í•˜ê²Œ í•„í„°
        terms = [t for t in terms if t and t not in QUERY_TERM_STOP]
        return terms[:5]

    # -------------------------
    # Main pipeline
    # -------------------------
    """
    get_ai_recommendations() ìˆ˜ì • ë²„ì „
    NoneType ì—ëŸ¬ ìˆ˜ì • - fallback ë¡œì§ ì •ë¦¬
    """

    # AIRecommendationService.pyì˜ get_ai_recommendations() ë©”ì„œë“œ ìˆ˜ì •

    async def get_ai_recommendations(self, user_prompt: str, user_id: int, top_n: int = 5) -> Dict:
        rid = str(uuid.uuid4())[:8]
        logger.info(f"[RID={rid}] ğŸ” AI ê²€ìƒ‰ ìš”ì²­: user_id={user_id}, prompt='{user_prompt}'")

        try:
            # Step 1: GPT íŒŒì‹±
            logger.info(f"[Step 1] GPT í”„ë¡¬í”„íŠ¸ íŒŒì‹±: {user_prompt}")
            parsed_query = await self.gpt_service.parse_search_query(user_prompt)

            # Taxonomy êµì •
            parsed_query = self._normalize_query_taxonomy(parsed_query)
            parsed_query = self._post_fix(user_prompt, parsed_query)
            parsed_query = self._guard_category_by_evidence(user_prompt, parsed_query)
            parsed_query = self._apply_vibe_prior(parsed_query)
            parsed_query["vibe"] = self._normalize_vibe(parsed_query.get("vibe"))

            # Step 2: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸
            logger.info(f"[Step 2] ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ: user_id={user_id}")
            user_context = await self._get_user_context(user_id)
            logger.info(f"[CTX] lat={user_context.get('latitude')} lng={user_context.get('longitude')}")

            # âœ… ì •ë³´ ë¶€ì¡± ì²´í¬
            kw = parsed_query.get("keywords") or []
            conf = float(parsed_query.get("confidence", 0) or 0)
            cat = parsed_query.get("category")
            sub = parsed_query.get("subcategory")
            vibe = parsed_query.get("vibe")
            ts = parsed_query.get("time_slot")
            loc_q = parsed_query.get("location_query")

            # âœ… ì´ˆì• ë§¤ ì¼€ì´ìŠ¤: SVD + Clarification í•¨ê»˜ ì œê³µ
            if conf < 0.6 and len(kw) == 0 and not cat and not sub and not vibe and not ts and not loc_q:
                logger.warning(f"âš ï¸ ì´ˆì• ë§¤ ê²€ìƒ‰ì–´ ê°ì§€ (conf={conf:.2f}): '{user_prompt}' â†’ SVD fallback + clarification")

                # SVD ê¸°ë°˜ ì¶”ì²œ 5ê°œ
                svd_data = await self._fallback_svd_recommendation(
                    user_id, user_prompt, parsed_query, top_n, user_context
                )

                # Clarification ì¹´ë“œ 1ê°œ ì¶”ê°€
                clarification_card = self._make_clarification_card(user_prompt, parsed_query, user_context)

                # âœ… SVD ì¶”ì²œ 5ê°œ + clarification 1ê°œ = ì´ 6ê°œ
                recommendations = svd_data.get("recommendations", [])[:top_n]
                recommendations.append(clarification_card)

                return {
                    "user_prompt": user_prompt,
                    "parsed_query": parsed_query,
                    "total_candidates": svd_data.get("total_candidates", 0),
                    "recommendations": recommendations,  # âœ… 6ê°œ
                    "search_trace": {
                        "steps": [],
                        "final_level": 0,
                        "final_label": "SVD_FALLBACK_WITH_CLARIFY",
                        "fallback": True
                    }
                }

            # Step 3: ì¿¼ë¦¬ ë³´ê°•
            enriched_query = await self.gpt_service.enrich_with_user_context(parsed_query, user_context)

            # Step 4: ê²€ìƒ‰
            trace_steps: list = []
            base_query = self._pre_relax_query_by_conf(enriched_query)

            # âœ… ë””ë²„ê¹… ë¡œê·¸
            logger.info(f"ğŸ”¥ğŸ”¥ğŸ”¥ [DEBUG] base_query í™•ì¸: {base_query}")
            logger.info(f"ğŸ”¥ğŸ”¥ğŸ”¥ [DEBUG] _search_with_relaxation í˜¸ì¶œ ì§ì „!")

            candidate_meetings = await self._search_with_relaxation(base_query, user_context, trace_steps,
                                                                    user_prompt)  # âœ… ì¶”ê°€

            # âœ… ì—¬ê¸° ì¶”ê°€!
            logger.info(f"ğŸ”¥ğŸ”¥ğŸ”¥ [DEBUG] _search_with_relaxation ì™„ë£Œ!")
            logger.info(f"ğŸ”¥ğŸ”¥ğŸ”¥ [DEBUG] candidate_meetings ê°œìˆ˜: {len(candidate_meetings) if candidate_meetings else 0}")

            # âœ… ê²€ìƒ‰ ê²°ê³¼ ì—†ìœ¼ë©´ SVD fallback
            if not candidate_meetings:
                logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - SVD ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ ëŒ€ì²´")
                data = await self._fallback_svd_recommendation(user_id, user_prompt, parsed_query, top_n, user_context)

                # fallbackë„ intent ë³´ì •
                intent = self._detect_intent(user_prompt, enriched_query)

                for rec in data.get("recommendations", []):
                    adjustment = self._apply_intent_adjustment(intent, rec, enriched_query)
                    new_score = rec.get("match_score", 0) + adjustment
                    rec["match_score"] = int(max(0, min(100, new_score)))
                    rec["intent"] = intent

                data["search_trace"] = {
                    "steps": trace_steps,
                    "final_level": trace_steps[-1]["level"] if trace_steps else 0,
                    "final_label": trace_steps[-1]["label"] if trace_steps else "L0 ì›ë³¸",
                    "fallback": True
                }
                return data

            query_terms = self._extract_query_terms(user_prompt, parsed_query)
            logger.info(f"[QUERY_TERMS] prompt='{user_prompt}' -> terms={query_terms}")

            # Step 5: AI ì ìˆ˜ ê³„ì‚°
            logger.info(f"[Step 5] AI ì ìˆ˜ ê³„ì‚°: {len(candidate_meetings)}ê°œ ëª¨ì„")

            intent = self._detect_intent(user_prompt, enriched_query)

            scored_meetings = await self._score_meetings(
                user_id, user_context, candidate_meetings, enriched_query, intent,
                user_prompt=user_prompt,
                query_terms=query_terms
            )

            # âœ… intent ë³´ì • ì ìš© + ê³„ì¸µë³„ ìƒí•œ
            n_total = len(scored_meetings)

            for m in scored_meetings:
                m["intent"] = intent

            # Step 6: ìƒìœ„ Nê°œ ì„ íƒ
            sorted_all = sorted(scored_meetings, key=lambda x: x["match_score"], reverse=True)

            # query-hit íŒì • (query_terms ê¸°ì¤€)
            def is_query_hit(rec: dict) -> bool:
                hay = f"{(rec.get('title') or '')} {(rec.get('subcategory') or '')} {(rec.get('category') or '')}".lower()
                for t in (query_terms or []):
                    if t and t.lower() in hay:
                        return True
                return False

            hits = [r for r in sorted_all if is_query_hit(r)]
            others = [r for r in sorted_all if not is_query_hit(r)]

            # âœ… Bì•ˆ: top_n ì¤‘ ìµœì†Œ 2ê°œëŠ” hitë¡œ ì±„ìš°ê³ , ë‚˜ë¨¸ì§€ëŠ” ì ìˆ˜ìˆœ ì¶”ì²œìœ¼ë¡œ ì±„ì›€
            must = 2 if top_n >= 4 else 1
            picked = []

            picked.extend(hits[:must])
            picked.extend([r for r in others if r not in picked])

            top_recommendations = picked[:top_n]

            # Step 7: Reasoning
            for rec in top_recommendations:
                if (not parsed_query.get("keywords")) or parsed_query.get("confidence", 0) < 0.6:
                    rec["reasoning"] = self._fallback_reasoning(rec, parsed_query)
                else:
                    rec["reasoning"] = await self._generate_reasoning(user_context, rec, parsed_query)

            logger.info("ğŸ TOP=%s", [
                (r.get("meeting_id"), r.get("title"), r.get("category"), r.get("subcategory"))
                for r in top_recommendations
            ])

            return {
                "user_prompt": user_prompt,
                "parsed_query": parsed_query,
                "total_candidates": len(candidate_meetings),
                "recommendations": top_recommendations,
                "search_trace": {
                    "steps": trace_steps,
                    "final_level": trace_steps[-1]["level"] if trace_steps else 0,
                    "final_label": trace_steps[-1]["label"] if trace_steps else "L0 ì›ë³¸",
                    "fallback": False
                }
            }

        except Exception as e:
            logger.error(f"âŒ AI ì¶”ì²œ ì‹¤íŒ¨: {e}", exc_info=True)  # âœ… exc_info ì¶”ê°€ë¡œ ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
            raise

    # -------------------------
    # Scoring (ë„ˆ ì½”ë“œ ê±°ì˜ ê·¸ëŒ€ë¡œ)
    # -------------------------
    # AIRecommendationService ì•ˆì— ìˆëŠ” _score_meetings()ë¥¼ ì´ ë²„ì „ìœ¼ë¡œ êµì²´í•˜ë©´ ë¨.
    # - /search ë­í‚¹: rankerë¡œ match_score ë§Œë“¤ê³  ì •ë ¬
    # - UIìš© predicted_rating: (ì„ íƒ) regressorë¡œ ê°™ì´ ë„£ì–´ì¤Œ
    # - ê¸°ì¡´ key_points ìœ ì§€
    """
    ì™„ì „í•œ _score_meetings() ë©”ì„œë“œ
    1ê°œ í›„ë³´ ì ˆëŒ€ ìƒí•œ 78%
    """

    """
    _score_meetings() ìµœì¢… ìˆ˜ì • ë²„ì „
    100% ì ˆëŒ€ ë°©ì§€ - ë™ì  ìƒí•œ ëŒ€í­ í•˜í–¥
    """

    # AIRecommendationService.pyì˜ _score_meetings() ë©”ì„œë“œ ìˆ˜ì •

    # AIRecommendationService.pyì˜ _score_meetings() ë©”ì„œë“œ ìˆ˜ì •

    async def _score_meetings(
            self,
            user_id: int,
            user_context: dict,
            candidate_meetings: list[dict],
            parsed_query: dict,
            intent: str,
            user_prompt: str = "",
            query_terms: Optional[list[str]] = None
    ) -> list[dict]:
        """AI ì ìˆ˜ ê³„ì‚° - ë™ì  ë°©ì§€ + ì°¨ë³„ì„± ê°•í™”"""

        def pick(d: dict, *keys, default=None):
            for k in keys:
                if k in d and d.get(k) is not None:
                    return d.get(k)
            return default

        if not model_loader.ranker or not model_loader.ranker.is_loaded():
            raise RuntimeError("LightGBM Ranker ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not model_loader.feature_builder:
            raise RuntimeError("FeatureBuilderê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        use_regressor_for_rating = bool(model_loader.regressor and model_loader.regressor.is_loaded())

        conf = float(parsed_query.get("confidence", 0) or 0)

        def dynamic_ceil(n: int, conf: float) -> int:
            """ë™ì  ìƒí•œ - í›„ë³´ê°€ ë§ì„ìˆ˜ë¡ ë‚®ì¶¤"""
            if n == 1:
                return 73
            elif n == 2:
                return 76
            elif n == 3:
                return 79
            elif n <= 5:
                return 82
            elif n <= 10:
                return 84
            elif n <= 30:  # âœ… ìƒˆë¡œ ì¶”ê°€
                return 85
            elif n <= 50:
                return 86
            else:
                return 87

        user_time_pref = (
                parsed_query.get("user_time_preference")
                or pick(user_context, "time_preference", "timePreference", default=None)
        )

        user = {
            "lat": pick(user_context, "lat", "latitude", default=None),
            "lng": pick(user_context, "lng", "longitude", default=None),
            "interests": pick(user_context, "interests", default=""),
            "time_preference": self._normalize_timeslot(user_time_pref),
            "user_location_pref": pick(user_context, "user_location_pref", "userLocationPref", default=None),
            "budget_type": self._normalize_budget_for_model(
                pick(user_context, "budget_type", "budgetType", default="value")
            ),
            "user_avg_rating": float(pick(user_context, "user_avg_rating", "userAvgRating", default=3.0)),
            "user_meeting_count": int(pick(user_context, "user_meeting_count", "userMeetingCount", default=0)),
            "user_rating_std": float(pick(user_context, "user_rating_std", "userRatingStd", default=0.5)),
        }

        rows, feats, valid_candidates = [], [], []
        for raw in candidate_meetings:
            try:
                m = self._normalize_meeting(raw)
                feat, x = model_loader.feature_builder.build(user, m)
                rows.append(x[0])
                feats.append(feat)
                valid_candidates.append(m)
            except Exception as e:
                logger.warning(f"âš ï¸ feature build ì‹¤íŒ¨ meeting_id={raw.get('meeting_id')}: {e}")
                continue

        if not rows:
            return []

        X = np.vstack(rows)
        rank_raw = model_loader.ranker.predict(X)
        raw_list = [float(v) for v in rank_raw]
        n = len(raw_list)

        ceil = dynamic_ceil(n, conf)
        logger.info(f"[SCORE] n={n}, conf={conf:.2f}, ceil={ceil}")

        rating_list = None
        if use_regressor_for_rating:
            try:
                preds = model_loader.regressor.predict(X)
                rating_list = [float(v) for v in preds]
            except Exception as e:
                logger.warning(f"âš ï¸ regressor rating ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")

        match_scores = [55] * n

        if n == 1:
            s = raw_list[0]
            base_score = 1.0 / (1.0 + math.exp(-s * 0.25))
            base_score = 58 + base_score * 15
            conf_bonus = conf * 3
            ms = base_score + conf_bonus
            ms = max(60, min(73, ms))
            match_scores[0] = int(round(ms))
            logger.info(
                f"[SCORE_1ê°œ] raw={s:.3f}, base={base_score:.1f}, conf={conf:.2f}, bonus={conf_bonus:.1f}, final={match_scores[0]}")

        elif n <= 10:
            base = [78, 74, 70, 66, 63, 60, 57, 55, 53, 51]
            order = sorted(range(n), key=lambda i: raw_list[i], reverse=True)

            top = raw_list[order[0]]
            bottom = raw_list[order[-1]]
            span = (top - bottom) if (top - bottom) != 0 else 1.0

            for rank, i in enumerate(order):
                b = base[rank] if rank < len(base) else 52
                t = (raw_list[i] - bottom) / span
                adj = (t - 0.5) * 6.0
                ms = b + adj
                ms = max(50, min(82, ms))
                ms = min(ms, ceil)
                match_scores[i] = int(round(ms))

        else:
            # âœ… í•µì‹¬ ê°œì„ : ë™ì  ë°©ì§€ ë¡œì§ ê°•í™”
            sorted_vals = sorted(raw_list)

            def percentile_midrank(x: float) -> float:
                lt = sum(1 for v in sorted_vals if v < x)
                eq = sum(1 for v in sorted_vals if v == x)
                p = (lt + 0.5 * eq) / n
                eps = 0.5 / n
                if p < eps:
                    p = eps
                if p > 1 - eps:
                    p = 1 - eps
                return p

            # âœ… 1. meeting_id ê¸°ë°˜ deterministic noise ì¶”ê°€
            for i, s in enumerate(raw_list):
                meeting_id = valid_candidates[i].get("meeting_id", i)

                p = percentile_midrank(float(s))

                # âœ… 2. meeting_id ê¸°ë°˜ ê³ ìœ  noise (deterministic)
                id_noise = (meeting_id % 1000) * 0.00001  # 0.00000 ~ 0.00999

                # âœ… 3. ìˆœì„œ ê¸°ë°˜ noise (ë™ì¼ percentile êµ¬ë¶„)
                order_noise = i * 0.0001  # 0.0000, 0.0001, 0.0002...

                p_adjusted = p + id_noise + order_noise
                p_adjusted = max(0.0, min(1.0, p_adjusted))

                # âœ… 4. stretch ê°•í™” (ìƒìœ„ê¶Œ ë” ë²Œë¦¼)
                p_final = max(0.0, min(1.0, 0.5 + (p_adjusted - 0.5) * 1.6))

                # âœ… 5. gamma ê°•í™” (ìƒìœ„ê¶Œ ë“œë¼ë§ˆí‹±í•˜ê²Œ)
                ms = match_from_percentile(p_final, floor=46, ceil=ceil, gamma=1.6)
                ms = min(ms, ceil)
                match_scores[i] = int(ms)

        # âœ… 6. ë³´ì • ë¡œì§ (ê¸°ì¡´ ìœ ì§€)
        results = []
        for idx, (m, feat, s) in enumerate(zip(valid_candidates, feats, raw_list)):
            ms = int(match_scores[idx])

            # ì‹œê°„ëŒ€ ë§¤ì¹­
            requested_ts = parsed_query.get("time_slot") or parsed_query.get("timeSlot")
            meeting_ts = m.get("time_slot")

            if requested_ts and meeting_ts:
                req_normalized = self._normalize_timeslot(requested_ts)
                meet_normalized = self._normalize_timeslot(meeting_ts)

                if req_normalized == meet_normalized:
                    ms += 10
                elif self._is_adjacent_timeslot(req_normalized, meet_normalized):
                    ms += 2
                else:
                    ms -= 15

            # location_query ë³´ì •
            location_query = parsed_query.get("location_query")
            if location_query:
                meeting_loc = str(m.get("location_name", "")).lower()
                query_loc = str(location_query).lower()
                query_keyword = query_loc.replace("ê·¼ì²˜", "").replace("ì£¼ë³€", "").replace("ì§‘", "").strip()

                if query_keyword and query_keyword in meeting_loc:
                    ms += 20
                elif any(keyword in meeting_loc for keyword in ["êµ¬", "ì—­", "ë™"]):
                    ms -= 5

            def _query_match_bonus(m: dict, q_terms: list[str]) -> float:
                if not q_terms:
                    return 0.0

                title = (m.get("title") or "").lower()
                sub = (m.get("subcategory") or "").lower()
                cat = (m.get("category") or "").lower()
                loc = (m.get("location_name") or "").lower()

                hay = f"{title} {sub} {cat} {loc}"

                hit = sum(1 for t in q_terms if t and t.lower() in hay)

                # âœ… í•µì‹¬: ë³´ë„ˆìŠ¤ ë” ì„¸ê²Œ!
                if hit >= 2:
                    return 30.0  # 25 â†’ 30
                if hit == 1:
                    return 22.0  # 18 â†’ 22

                # ì™„ì „ ë¬´ê´€ì´ë©´ íŒ¨ë„í‹° ê°•í™”
                return -12.0  # -6 â†’ -12

            requested_sub = (parsed_query.get("subcategory") or "").strip()
            if requested_sub and conf >= 0.7:
                meet_sub = (m.get("subcategory") or "").strip()
                if meet_sub == requested_sub:
                    ms += 18  # âœ… ì¶•êµ¬ë©´ í¬ê²Œ ê°€ì‚°
                else:
                    ms -= 25  # âœ… ì¶•êµ¬ ì•„ë‹ˆë©´ í¬ê²Œ ê°ì  (ëŸ¬ë‹ 1ìœ„ ë°©ì§€ í•µì‹¬)

            # keyword íŒíŠ¸
            # --- query terms bonus (Bì•ˆ í•µì‹¬) ---
            q_terms = query_terms or []
            ms += _query_match_bonus(m, q_terms)

            keywords = clean_keywords(parsed_query.get("keywords") or [])
            if keywords:
                text = (
                    f"{m.get('title', '')} {m.get('location_name', '')} {m.get('location_address', '')} "
                    f"{m.get('subcategory', '')} {m.get('vibe', '')}"
                ).lower()

                hit = sum(1 for k in keywords if k in text)
                ms += min(hit * 2, 5)
                # âœ… (ì¶”ê°€) intent ë³´ì •ì€ ì—¬ê¸°ì„œ! (get_ai_recommendationsì—ì„œ ì œê±°í–ˆìœ¼ë‹ˆê¹Œ)

            ms += float(self._apply_intent_adjustment(intent, m, parsed_query))

            # âœ… (ì¶”ê°€) tie-break: meeting_id ê¸°ë°˜ deterministic jitter
            # - ê°™ì€ ì ìˆ˜(ë˜ëŠ” ê°™ì€ ë¼ìš´ë”© ê²°ê³¼) ëª°ë¦¼ì„ ë°©ì§€
            mid = int(m.get("meeting_id") or 0)
            ms += ((mid % 97) - 48) * 0.02  # ì•½ -0.96 ~ +0.98

            # âœ… ìµœì¢… ìº¡ì€ ì—¬ê¸°ì„œ 1ë²ˆë§Œ
            ms = min(ms, float(ceil))
            ms = max(0.0, min(100.0, ms))

            ms_int = int(round(ms))

            # ë§¤ì¹­ ë ˆë²¨
            if ms_int >= 85:
                lvl = "VERY_HIGH"
            elif ms_int >= 78:
                lvl = "HIGH"
            elif ms_int >= 65:
                lvl = "MEDIUM"
            else:
                lvl = "LOW"

            item = {
                **m,
                "rank_raw": round(float(s), 4),
                "match_score": ms_int,
                "meetingId": m.get("meeting_id"),
                "meeting_id": m.get("meeting_id"),
                "match_level": lvl,
                "key_points": self._build_key_points_from_feat(feat),
                "score_meta": {
                    "n_candidates": n,
                    "confidence": round(conf, 3),
                    "ceil": int(ceil),
                }
            }

            if rating_list is not None:
                item["predicted_rating"] = round(float(rating_list[idx]), 3)

            results.append(item)

        results.sort(key=lambda x: x.get("match_score", 0), reverse=True)
        return results

    def _build_key_points_from_feat(self, feat: dict) -> list[str]:
        points = []
        if feat.get("distance_km", 999) <= 3:
            points.append(f"ê°€ê¹Œìš´ ê±°ë¦¬({feat['distance_km']:.1f}km)")
        if feat.get("time_match") == 1.0:
            points.append("ì„ í˜¸ ì‹œê°„ëŒ€ ì¼ì¹˜")
        if feat.get("location_type_match") == 1.0:
            points.append("ì‹¤ë‚´/ì•¼ì™¸ ì„ í˜¸ ì¼ì¹˜")
        if feat.get("cost_match_score", 0) >= 0.7:
            points.append("ì˜ˆì‚°ì— ì˜ ë§ìŒ")
        if feat.get("interest_match_score", 0) >= 0.5:
            points.append("ê´€ì‹¬ì‚¬ ë§¤ì¹­")
        return points[:3]

    # -------------------------
    # User context / Reasoning / Fallback / Batch
    # -------------------------
    async def _get_user_context(self, user_id: int) -> Dict:
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(f"{self.spring_boot_url}/api/users/{user_id}/context")
                response.raise_for_status()
                ctx = response.json()
                logger.info(f"âœ… ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì„±ê³µ: userId={user_id}")
                return ctx
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "user_id": user_id,
                "latitude": 37.5665,
                "longitude": 126.9780,
                "interests": "",
                "time_preference": "",
                "budget_type": "VALUE",
                "user_avg_rating": 0.0,
                "user_meeting_count": 0,
                "user_rating_std": 0.0
            }

    async def _generate_reasoning(self, user_context: Dict, meeting: Dict, parsed_query: Dict) -> str:
        """
        GPTë¥¼ í™œìš©í•œ ë™ì ì´ê³  ê³µê° ê°€ëŠ¥í•œ ì¶”ì²œ ì´ìœ  ìƒì„±
        """
        try:
            # âœ… None ì²´í¬ë¥¼ í¬í•¨í•œ ì•ˆì „í•œ ê°’ ì¶”ì¶œ
            user_prompt_keywords = " ".join(parsed_query.get("keywords", []))
            category = meeting.get("category") or ""
            subcategory = meeting.get("subcategory") or ""
            location = meeting.get("location_name") or "ë¯¸ì •"
            distance = meeting.get("distance_km") if meeting.get("distance_km") is not None else 0
            cost = meeting.get("expected_cost") if meeting.get("expected_cost") is not None else 0
            participants = meeting.get("current_participants") if meeting.get("current_participants") is not None else 0
            max_participants = meeting.get("max_participants") if meeting.get("max_participants") is not None else 10
            vibe = meeting.get("vibe") or ""

            # âœ… GPT í”„ë¡¬í”„íŠ¸
            prompt = f"""
    ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ AI ì¶”ì²œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ìƒí™©ê³¼ ê°ì •ì„ ì´í•´í•˜ê³ , ì™œ ì´ ëª¨ì„ì´ ë”± ë§ëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.

    **ì‚¬ìš©ì í‚¤ì›Œë“œ:** {user_prompt_keywords}

    **ì¶”ì²œ ëª¨ì„:**
    - ì œëª©: {meeting.get('title', 'ì œëª© ì—†ìŒ')}
    - ì¹´í…Œê³ ë¦¬: {category} - {subcategory}
    - ë¶„ìœ„ê¸°: {vibe}
    - ìœ„ì¹˜: {location} ({distance:.1f}km)
    - ë¹„ìš©: {cost:,}ì›
    - ì°¸ê°€ì: {participants}/{max_participants}ëª…

    **ì‘ì„± ê·œì¹™:**
    1. ì‚¬ìš©ìì˜ ê°ì •/ìƒí™©ì— ê³µê°í•˜ëŠ” í•œ ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘
    2. ì´ ëª¨ì„ì˜ ë§¤ë ¥ í¬ì¸íŠ¸ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…
    3. ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ (ì¡´ëŒ“ë§ + ë°˜ë§ ì„ì–´ì„œ)
    4. ì´ëª¨ì§€ 1-2ê°œë§Œ ì‚¬ìš© (ê³¼í•˜ì§€ ì•Šê²Œ)
    5. ì´ 3-4ë¬¸ì¥, 80-120ì ì´ë‚´

    **ì¢‹ì€ ì˜ˆì‹œ:**
    - "ì˜¤ëŠ˜ í˜ë“œì…¨ì£ ? ğŸ˜Š ì¡°ìš©í•œ ì¹´í˜ì—ì„œ ë¸ŒëŸ°ì¹˜ ë¨¹ìœ¼ë©´ì„œ ë¨¸ë¦¬ ì¢€ ì‹íˆëŠ” ê±´ ì–´ë–¨ê¹Œìš”? í™ëŒ€ ì¹´í˜ëŠ” ë¶„ìœ„ê¸°ë„ ì•„ëŠ‘í•˜ê³  2.3km ê±°ë¦¬ë¼ ë¶€ë‹´ ì—†ì–´ìš”!"
    - "ë”± ì ë‹¹íˆ ëª¸ í’€ê³  ì‹¶ì„ ë•Œë„¤ìš”! ğŸƒ í•œê°•ì—ì„œ 5km ê°€ë³ê²Œ ë›°ë©´ì„œ ê°™ì´ ë‹¬ë¦¬ëŠ” ì‚¬ëŒë“¤ì´ë‘ ìˆ˜ë‹¤ë„ ë–¨ë©´ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ í™• í’€ë ¤ìš”."
    - "ê¸°ë¶„ì „í™˜ì—” ì „ì‹œíšŒë§Œ í•œ ê²Œ ì—†ì£ ! ğŸ¨ ì„±ìˆ˜ë™ ê°¤ëŸ¬ë¦¬ëŠ” ë¬´ë£Œ ì…ì¥ì´ê³  ì‘í’ˆ ë³´ë©´ì„œ ê°ì„± ì¶©ì „í•˜ê¸° ë”±ì´ì—ìš”."

    **ì´ì œ ì‘ì„±í•˜ì„¸ìš” (ì¶”ì²œ ì´ìœ ë§Œ, ë‹¤ë¥¸ ë§ ì—†ì´):**
    """

            # # âœ… await ì œê±° - ë™ê¸° í˜¸ì¶œ
            # response = self.gpt_service.client.chat.completions.create(
            #     model="gpt-4o-mini",
            #     messages=[
            #
            #     ],
            #     temperature=0.7,
            #     max_tokens=200
            # )
            #
            # reasoning = response.choices[0].message.content.strip()
            # logger.info(f"âœ… GPT reasoning ìƒì„±: {reasoning[:50]}...")
            # return reasoning

            def _call():
                return self.gpt_service.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "system", "content": "ë‹¹ì‹ ì€ ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ AI ì¶”ì²œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}],
                    temperature=0.7,
                    max_tokens=200
                )

            response = await anyio.to_thread.run_sync(_call)
            reasoning = response.choices[0].message.content.strip()
            return reasoning

        except Exception as e:
            logger.error(f"âš ï¸ GPT reasoning ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}")
            return self._fallback_reasoning(meeting, parsed_query)

    def _fallback_reasoning(self, meeting: Dict, parsed_query: Dict) -> str:
        """GPT ì‹¤íŒ¨ ì‹œ í…œí”Œë¦¿ ê¸°ë°˜ reasoning"""

        # âœ… None ì²´í¬ë¥¼ í¬í•¨í•œ ì•ˆì „í•œ ê°’ ì¶”ì¶œ
        category = meeting.get("category") or ""
        subcategory = meeting.get("subcategory") or ""
        location = meeting.get("location_name") or "ë¯¸ì •"
        distance = meeting.get("distance_km") if meeting.get("distance_km") is not None else 0
        cost = meeting.get("expected_cost") if meeting.get("expected_cost") is not None else 0
        participants = meeting.get("current_participants") if meeting.get("current_participants") is not None else 0

        templates = {
            "ì¹´í˜": [
                f"ì¡°ìš©í•œ {location}ì—ì„œ íë§ íƒ€ì„ ì–´ë•Œìš”? â˜• {distance:.1f}km ê±°ë¦¬ë¼ ë¶€ë‹´ ì—†ì´ ë‹¤ë…€ì˜¬ ìˆ˜ ìˆì–´ìš”!",
                f"ì¹´í˜ì—ì„œ ë¸ŒëŸ°ì¹˜ ë¨¹ìœ¼ë©´ì„œ ì—¬ìœ ë¡­ê²Œ ì‰¬ëŠ” ê±´ ì–´ë–¨ê¹Œìš”? í˜„ì¬ {participants}ëª…ì´ ì°¸ì—¬ ì¤‘ì´ë¼ í¸ì•ˆí•œ ë¶„ìœ„ê¸°ì˜ˆìš”.",
            ],
            "ìŠ¤í¬ì¸ ": [
                f"ê°€ë³ê²Œ ëª¸ í’€ë©´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ ë‚ ë ¤ë²„ë¦¬ê¸° ì¢‹ì•„ìš”! ğŸƒ {location}ì—ì„œ í•¨ê»˜ ìš´ë™í•˜ë©´ ë” ì¬ë°Œì–´ìš”.",
                f"ì ë‹¹íˆ ë•€ í˜ë¦¬ë©´ì„œ ê¸°ë¶„ì „í™˜í•˜ê¸° ë”±! {participants}ëª…ì´ë‘ ê°™ì´ í•˜ë©´ ë™ê¸°ë¶€ì—¬ë„ ë˜ê³ ìš”.",
            ],
            "ë§›ì§‘": [
                f"ë§›ìˆëŠ” ê±° ë¨¹ìœ¼ë©´ì„œ íë§í•˜ëŠ” ê²Œ ìµœê³ ì£ ! ğŸ½ï¸ {subcategory} ì¢‹ì•„í•˜ì‹œë©´ ê°•ì¶”ì˜ˆìš”.",
                f"{cost:,}ì›ìœ¼ë¡œ ë§›ìˆëŠ” ìŒì‹ ë¨¹ìœ¼ë©´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ í’€ ìˆ˜ ìˆì–´ìš”!",
            ],
            "ë¬¸í™”ì˜ˆìˆ ": [
                f"ê°ì„± ì¶©ì „ì´ í•„ìš”í•  ë•Œ! ğŸ¨ {location}ì—ì„œ ì—¬ìœ ë¡­ê²Œ ì˜ˆìˆ  ê°ìƒí•˜ë©´ ë§ˆìŒì´ í¸ì•ˆí•´ì ¸ìš”.",
                f"ì¡°ìš©íˆ ì „ì‹œ ë³´ë©´ì„œ ë¨¸ë¦¬ ë¹„ìš°ê¸° ë”± ì¢‹ì€ ëª¨ì„ì´ì—ìš”. {distance:.1f}km ê±°ë¦¬ë¼ ê°€ê¹ê³ ìš”.",
            ],
            "ì†Œì…œ": [
                f"ê°€ë³ê²Œ ë†€ë©´ì„œ ê¸°ë¶„ì „í™˜! ğŸ® {subcategory} í•˜ë©´ì„œ ì›ƒë‹¤ ë³´ë©´ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ í™• í’€ë ¤ìš”.",
                f"{participants}ëª…ì´ë‘ í•¨ê»˜í•˜ëŠ” {subcategory} ëª¨ì„! ë¶€ë‹´ ì—†ì´ ì¦ê¸°ê¸° ì¢‹ì•„ìš”.",
            ],
        }

        import random
        options = templates.get(category, [f"ì´ ëª¨ì„ì€ ë‹¹ì‹ ì˜ ì·¨í–¥ê³¼ ì˜ ë§ì„ ê²ƒ ê°™ì•„ìš”! ğŸ˜Š {location}ì—ì„œ {distance:.1f}km ê±°ë¦¬ì˜ˆìš”."])
        return random.choice(options)

    async def _fallback_svd_recommendation(
            self,
            user_id: int,
            user_prompt: str,
            parsed_query: Dict,
            top_n: int,
            user_context: Dict,  # âœ… ì¶”ê°€
    ) -> Dict:
        if not model_loader.svd or not model_loader.svd.is_loaded():
            raise RuntimeError("SVD ëª¨ë¸ ë¡œë“œë˜ì§€ ì•ŠìŒ")

        svd_recommendations = await model_loader.svd.recommend(user_id=user_id, top_n=top_n * 2)
        meeting_ids = [int(mid) for mid, _ in svd_recommendations]
        meetings = await self._get_meetings_by_ids(meeting_ids)

        # âœ… fallbackì—ì„œë„ ìœ ì €ì¢Œí‘œ ê¸°ë°˜ ê±°ë¦¬ ê³„ì‚° ì£¼ì…
        meetings = self._inject_distance_km(meetings, user_context)

        scored = []
        for meeting in meetings:
            # meeting_id í‚¤ í˜¼ìš© ëŒ€ì‘
            m_id = meeting.get("meeting_id") or meeting.get("meetingId")
            svd_score = next((score for mid, score in svd_recommendations if int(mid) == int(m_id)), 3.5)

            scored.append({
                **meeting,
                "match_score": min(100, int(float(svd_score) * 20)),
                "predicted_rating": round(float(svd_score), 1),
                "svd_score": round(float(svd_score), 2),
                "key_points": ["SVD í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì¶”ì²œ"],
                "reasoning": "ê³¼ê±° ì°¸ì—¬ ì´ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œëœ ëª¨ì„ì…ë‹ˆë‹¤."
            })

        return {
            "user_prompt": user_prompt,
            "parsed_query": parsed_query,
            "total_candidates": len(scored),
            "recommendations": scored[:top_n],
            "fallback": True
        }

    async def _get_meetings_by_ids(self, meeting_ids: List[int]) -> List[Dict]:
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.post(
                    f"{self.spring_boot_url}/api/meetings/batch",
                    json={"meetingIds": meeting_ids}
                )
            if response.status_code == 200:
                return response.json().get("meetings", [])
            return []
        except Exception as e:
            logger.error(f"âš ï¸ ëª¨ì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def _normalize_meeting(self, m: dict) -> dict:
        title = (m.get("title") or "").strip()
        sub = (m.get("subcategory") or "").strip()
        cat = (m.get("category") or "").strip()

        # âœ… title ê¸°ë°˜ ìŠ¤í¬ì¸  subcategory ìë™ êµì • (ë°ì´í„° ì˜¤ì—¼ ë°©ì–´)
        if cat == "ìŠ¤í¬ì¸ " and title:
            t = title.lower()
            if "ëŸ¬ë‹" in t or "ë‹¬ë¦¬ê¸°" in t:
                sub = "ëŸ¬ë‹"
            elif "ì¶•êµ¬" in t or "í’‹ì‚´" in t:
                sub = "ì¶•êµ¬"
            elif "ë°°ë“œë¯¼í„´" in t:
                sub = "ë°°ë“œë¯¼í„´"
            elif "í´ë¼ì´ë°" in t:
                sub = "í´ë¼ì´ë°"

        return {
            "meeting_id": m.get("meeting_id") or m.get("meetingId"),
            "lat": m.get("latitude") or m.get("lat"),
            "lng": m.get("longitude") or m.get("lng"),
            "category": cat or "",
            "subcategory": sub or "",  # âœ… ì—¬ê¸° subê°€ êµì •ëœ ê°’
            "time_slot": self._normalize_timeslot(m.get("time_slot") or m.get("timeSlot")),
            "meeting_location_type": self._normalize_location_type(m.get("location_type") or m.get("locationType")),
            "vibe": m.get("vibe", "") or "",
            "meeting_participant_count": m.get("current_participants") or m.get("currentParticipants") or 0,
            "expected_cost": m.get("expected_cost") or m.get("expectedCost") or 0,
            "meeting_avg_rating": m.get("avg_rating") or m.get("avgRating") or 0.0,
            "meeting_rating_count": m.get("rating_count") or m.get("ratingCount") or 0,
            "distance_km": m.get("distance_km") or m.get("distanceKm"),
            "title": m.get("title"),
            "image_url": m.get("image_url") or m.get("imageUrl"),
            "location_name": m.get("location_name") or m.get("locationName"),
            "location_address": m.get("location_address") or m.get("locationAddress"),
            "meeting_time": m.get("meeting_time") or m.get("meetingTime"),
            "max_participants": m.get("max_participants") or m.get("maxParticipants") or 10,
            "current_participants": m.get("current_participants") or m.get("currentParticipants") or 0,
        }

    def _make_clarification_card(self, user_prompt: str, parsed_query: dict, user_context: dict) -> dict:
        # ìœ ì € ìœ„ì¹˜ê°€ ìˆìœ¼ë©´ â€œì§‘ ê·¼ì²˜â€ ê°™ì€ ë¬¸êµ¬ë„ ê°€ëŠ¥
        # (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ í…ìŠ¤íŠ¸ë¡œë§Œ)
        return {
            "meeting_id": -1,
            "title": "ì–´ë–¤ ê±¸ í•˜ê³  ì‹¶ì€ì§€ í•œ ê°€ì§€ë§Œ ë” ì•Œë ¤ì¤˜ìš” ğŸ™‚",
            "category": "SYSTEM",
            "subcategory": "CLARIFY",
            "location_name": "ì¶”ì²œì„ ìœ„í•´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•´ìš”",
            "image_url": None,

            "match_score": 0,
            "match_level": "INFO",
            "predicted_rating": None,

            "key_points": [
                "ì˜ˆ: ì§‘ì—ì„œ ìš”ë¦¬ ê°™ì´ í•˜ê¸°",
                "ì˜ˆ: ì§‘ì—ì„œ ìŠ¤í„°ë””/ê³µë¶€",
                "ì˜ˆ: ì§‘ ê·¼ì²˜ ì¹´í˜ì—ì„œ ë¸ŒëŸ°ì¹˜",
            ],
            "reasoning": (
                f"ì§€ê¸ˆ ì…ë ¥ì€ '{user_prompt}'ë¼ì„œ ì¶”ì²œ ë²”ìœ„ë¥¼ ì¢íˆê¸° ì–´ë ¤ì›Œìš”. "
                "ì›í•˜ëŠ” í™œë™(ìš”ë¦¬/ìŠ¤í„°ë””/ì˜í™”/ìš´ë™ ë“±)ì´ë‚˜ ì§€ì—­(í™ëŒ€/ì„±ìˆ˜ ë“±) ì¤‘ 1ê°œë§Œ ë” ë§í•´ì¤˜ìš”!"
            ),
            "is_clarification": True,
            "intent": "NEUTRAL",
        }

    def _pre_relax_query_by_conf(self, q: dict) -> dict:
        """
        L0 ìì²´ë¥¼ confidence ê¸°ë°˜ìœ¼ë¡œ ì™„í™”
        âœ… categoryëŠ” 0.5 ì´ìƒì´ë©´ ìœ ì§€í•˜ë„ë¡ ì™„í™”
        """
        conf = float(q.get("confidence", 0) or 0)
        qq = dict(q)

        # âœ… 0.5 â†’ 0.5ë¡œ í•˜í–¥ (GPTê°€ 0.5~0.6ìœ¼ë¡œ ì£¼ëŠ” ê²½ìš° ë§ìŒ)
        if conf < 0.5:  # â† 0.65 â†’ 0.5
            qq.pop("category", None)

        # subcategoryëŠ” 0.7 ë¯¸ë§Œì´ë©´ ì œê±° (ê¸°ì¡´ ìœ ì§€)
        if conf < 0.7:
            qq.pop("subcategory", None)

        # vibe-only ê²€ìƒ‰(ì¹´í…Œê³ ë¦¬/í‚¤ì›Œë“œ ì—†ìŒ)ì—ì„œëŠ” vibeë¥¼ ìœ ì§€í•´ì•¼ í•¨
        if conf < 0.65:
            if qq.get("category") or (qq.get("keywords") and len(qq.get("keywords")) > 0):
                qq.pop("vibe", None)
            # else: vibeë§Œ ìˆëŠ” ì¼€ì´ìŠ¤ëŠ” ìœ ì§€

        # time_slotì€ 0.9 ì´ìƒì¼ ë•Œë§Œ (ê¸°ì¡´ ìœ ì§€)
        # if conf < 0.9:
        #     qq.pop("time_slot", None)
        #     qq.pop("timeSlot", None)

        return qq

    # -------------------------
    # Distance utils (fallbackì—ì„œë„ ê±°ë¦¬ ê³„ì‚°)
    # -------------------------
    def _haversine_km(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """ë‘ ì¢Œí‘œ ê°„ ê±°ë¦¬(km)."""
        R = 6371.0
        p1, p2 = math.radians(lat1), math.radians(lat2)
        d1 = math.radians(lat2 - lat1)
        d2 = math.radians(lon2 - lon1)
        a = (math.sin(d1 / 2) ** 2) + math.cos(p1) * math.cos(p2) * (math.sin(d2 / 2) ** 2)
        return 2 * R * math.asin(math.sqrt(a))

    def _inject_distance_km(self, meetings: List[Dict], user_ctx: Dict) -> List[Dict]:
        """meetingsì— distance_kmì´ ì—†ìœ¼ë©´ ìœ ì €ì¢Œí‘œë¡œ ê³„ì‚°í•´ì„œ ë„£ì–´ì¤Œ."""

        u_lat = user_ctx.get("latitude") or user_ctx.get("lat")
        u_lng = user_ctx.get("longitude") or user_ctx.get("lng")

        if u_lat is None or u_lng is None:
            return meetings

        out = []
        for m in meetings or []:
            # ì´ë¯¸ springì—ì„œ ë‚´ë ¤ì¤€ distanceê°€ ìˆìœ¼ë©´ ìœ ì§€
            if m.get("distance_km") is not None or m.get("distanceKm") is not None:
                out.append(m)
                continue

            m_lat = m.get("latitude") or m.get("lat")
            m_lng = m.get("longitude") or m.get("lng")

            if m_lat is None or m_lng is None:
                out.append(m)
                continue

            try:
                d = self._haversine_km(float(u_lat), float(u_lng), float(m_lat), float(m_lng))
                mm = dict(m)
                mm["distance_km"] = round(float(d), 3)  # UIëŠ” 0.1ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ë³´ì—¬ì£¼ë©´ ë¨
                out.append(mm)
            except Exception:
                out.append(m)

        return out

    # def _clean_keywords(self, keywords: Optional[list[str]]) -> list[str]:
    #     if not keywords:
    #         return []
    #
    #     stop = {
    #         # ìš”ì²­/ì¶”ì„ìƒˆ
    #         "ì¶”ì²œ", "ì¶”ì²œí•´ì¤˜", "ì¶”ì²œí•´ì£¼ì„¸ìš”", "í•´ì¤˜", "í•´ì£¼ì„¸ìš”",
    #         "ê·¸ëƒ¥", "ì¢€", "í•œë²ˆ", "ê°™ì´", "ìš”ì¦˜",
    #
    #         # ì• ë§¤ í”„ë¡¬í”„íŠ¸ ì „ìš©
    #         "ê°ˆë§Œí•œê³³", "ê°ˆë§Œí•œ", "ê°ˆê³³", "ê°€ë³¼ë§Œí•œ", "ì–´ë””", "ë­í•˜ì§€", "ë­í• ê¹Œ", "ì‹¬ì‹¬í•´",
    #         "íšŒì‚¬", "í‡´ê·¼", "ëë‚˜ê³ ", "í‡´ê·¼í›„", "í‡´ê·¼í•˜ê³ ", "ëë‚˜ë©´",
    #
    #         # âœ… ìƒˆë¡œ ì¶”ê°€: "ë‚˜ê°€ë‹¤" ê´€ë ¨ ë¶ˆí•„ìš” í‚¤ì›Œë“œ
    #         "ë‚˜ê°€ê³ ì‹¶ë‹¤", "ë‚˜ê°€ë‹¤", "ì™¸ì¶œ", "ì‹¶ë‹¤", "í•˜ê³ ì‹¶ë‹¤",
    #
    #         # ë²”ìš© ìœ„ì¹˜
    #         "ê·¼ì²˜", "ì£¼ë³€", "ì§‘", "ì§‘ê·¼ì²˜", "ë‚´ê·¼ì²˜",
    #
    #         # âœ… ì¹´í…Œê³ ë¦¬ëª… (ì¤‘ë³µ ë°©ì§€)
    #         "ì†Œì…œ", "ìŠ¤í¬ì¸ ", "ì¹´í˜", "ë§›ì§‘", "ë¬¸í™”ì˜ˆìˆ ", "ìŠ¤í„°ë””", "ì·¨ë¯¸í™œë™",
    #     }
    #
    #     cleaned = []
    #     for k in keywords:
    #         if not k:
    #             continue
    #         w = str(k).strip()
    #         w = w.replace(" ", "")
    #         if len(w) < 2:
    #             continue
    #         if w in stop:
    #             continue
    #         cleaned.append(w)
    #
    #     # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
    #     seen = set()
    #     out = []
    #     for w in cleaned:
    #         if w not in seen:
    #             out.append(w)
    #             seen.add(w)
    #     return out

    def _is_ambiguous_prompt(self, user_prompt: str, parsed_query: dict) -> bool:
        text = (user_prompt or "").lower()
        conf = float(parsed_query.get("confidence", 0) or 0)

        ambiguous_phrases = [
            "ê°ˆë§Œí•œê³³", "ê°€ë³¼ë§Œí•œ", "ë­í•˜ì§€", "ë­í• ê¹Œ", "ì‹¬ì‹¬", "ì¶”ì²œ", "ì•„ë¬´ê±°ë‚˜",
            "í‡´ê·¼", "íšŒì‚¬ë", "ëë‚˜ê³ ", "í‡´ê·¼í›„"
        ]

        # 1) confidence ë‚®ê³ 
        if conf <= 0.45:
            # 2) í™œë™ ëª…ì‚¬(ì¹´í˜/ëŸ¬ë‹/ì „ì‹œ/ë³´ë“œê²Œì„ ë“±)ê°€ ì—†ë‹¤ë©´ ì• ë§¤ë¡œ ë³¸ë‹¤
            has_category = bool(parsed_query.get("category"))
            kws = parsed_query.get("keywords") or []
            # keywordë„ ì˜ë¯¸ ì—†ëŠ” ê²ƒë§Œì´ë©´ ì• ë§¤
            if (not has_category) and (len(kws) <= 2 or any(p in text for p in ambiguous_phrases)):
                return True

        # phraseë¡œë„ ì• ë§¤ íŒì •
        if any(p in text for p in ambiguous_phrases) and not parsed_query.get("category"):
            return True

        return False


    def _is_near_me_phrase(self, q: str | None) -> bool:
        if not q:
            return False
        s = str(q).strip().lower()
        return ("ê·¼ì²˜" in s) or ("ì£¼ë³€" in s) or ("ì§‘" in s) or ("ë‚´ ê·¼ì²˜" in s)

    NEGATION_PATTERNS = [
        r"(ë§ê³ |ë¹¼ê³ |ì œì™¸|ë§ê³¤|ì•„ë‹ˆê³ |ë§ê³ ëŠ”|ë§ê³ ìš”|ë§ê³ ì„œ)",
        r"(ë§ê³ \s*ë‹¤ë¥¸|ë¹¼ê³ \s*ë‹¤ë¥¸|ì œì™¸í•˜ê³ )"
    ]

    def _has_exclusion(self, text: str) -> bool:
        if not text:
            return False
        t = text.lower().strip()
        return any(re.search(pat, t) for pat in self.NEGATION_PATTERNS)

    def _excludes_food(self, text: str) -> bool:
        """'ë¨¹/ì‹ì‚¬/ë°¥'ì´ ë“±ì¥í•˜ì§€ë§Œ 'ë§ê³ /ì œì™¸/ë¹¼ê³ 'ë¡œ ë¶€ì •ë˜ëŠ” ì¼€ì´ìŠ¤."""
        t = (text or "").lower()
        if not self._has_exclusion(t):
            return False
        food_words = ["ë¨¹", "ì‹ì‚¬", "ë°¥", "ë§›ì§‘", "ìŒì‹", "ì¹´í˜", "ë¸ŒëŸ°ì¹˜", "ë””ì €íŠ¸"]
        return any(w in t for w in food_words)

    # def _post_fix(self, user_prompt: str, parsed: dict) -> dict:
    #     """GPT íŒŒì‹± í›„ ë³´ì •"""
    #     text = user_prompt.lower().strip()
    #
    #     # âœ… ì„±ë³„ í‚¤ì›Œë“œ ê°ì§€
    #     male_keywords = ["ë‚¨ì", "ë‚¨ì„±", "ë‚¨ìê°€", "ë‚¨ì„±ì´"]
    #     female_keywords = ["ì—¬ì", "ì—¬ì„±", "ì—¬ìê°€", "ì—¬ì„±ì´"]
    #
    #     has_male = any(k in text for k in male_keywords)
    #     has_female = any(k in text for k in female_keywords)
    #
    #     # âœ… ë‚¨ì â†’ ìŠ¤í¬ì¸ /ì†Œì…œ(ë‹¹êµ¬/ë³¼ë§) ìš°ì„ 
    #     if has_male and not has_female:
    #         if parsed.get("category") == "ì†Œì…œ":
    #             # ì†Œì…œ ìœ ì§€í•˜ë˜, subcategory íŒíŠ¸
    #             parsed["keywords"] = ["ë‹¹êµ¬", "ë³¼ë§", "íƒêµ¬", "ì¶•êµ¬"]
    #             parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.7)
    #         elif not parsed.get("category"):
    #             parsed["category"] = "ìŠ¤í¬ì¸ "
    #             parsed["confidence"] = 0.6
    #
    #         logger.info(f"[POST_FIX] ë‚¨ì í‚¤ì›Œë“œ ê°ì§€ â†’ category={parsed.get('category')}, keywords={parsed.get('keywords')}")
    #
    #     # âœ… ì—¬ì â†’ ì¹´í˜/ë¬¸í™”ì˜ˆìˆ /ì·¨ë¯¸í™œë™ ìš°ì„ 
    #     elif has_female and not has_male:
    #         if parsed.get("category") == "ì†Œì…œ":
    #             parsed["category"] = "ì¹´í˜"  # ì†Œì…œ â†’ ì¹´í˜ë¡œ ë³€ê²½
    #             parsed["vibe"] = "ì—¬ìœ ë¡œìš´"
    #             parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.65)
    #         elif not parsed.get("category"):
    #             parsed["category"] = "ì¹´í˜"
    #             parsed["confidence"] = 0.6
    #
    #         logger.info(f"[POST_FIX] ì—¬ì í‚¤ì›Œë“œ ê°ì§€ â†’ category={parsed.get('category')}")
    #
    #         return parsed
    #
    #     # âœ… [NEW] ì‚¬ì§„/ì´¬ì˜ ì˜ë„ ê°•ì œ
    #     photo_words = ["ì‚¬ì§„", "ì´¬ì˜", "í¬í† ", "ì¹´ë©”ë¼", "í•„ì¹´", "ìŠ¤ëƒ…", "ì¸ìƒìƒ·"]
    #     if any(w in text for w in photo_words):
    #         parsed["category"] = "ë¬¸í™”ì˜ˆìˆ "
    #         parsed["subcategory"] = "ì‚¬ì§„ì´¬ì˜"  # â† ì´ê²Œ DBì— ìˆìœ¼ë©´ ì„¤ì •
    #         parsed["vibe"] = parsed.get("vibe") or "ì¦ê±°ìš´"
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0) or 0), 0.75)
    #
    #         logger.info("[POST_FIX] ì‚¬ì§„/ì´¬ì˜ ê°ì§€ â†’ category=ë¬¸í™”ì˜ˆìˆ , subcategory=ì‚¬ì§„ì´¬ì˜")
    #         return parsed
    #
    #     brain_words = ["ë¨¸ë¦¬", "ë¨¸ë¦¬ì“°", "ë‘ë‡Œ", "ì¶”ë¦¬", "ì „ëµ", "í¼ì¦", "í€´ì¦ˆ", "ë°©íƒˆì¶œ", "ë³´ë“œê²Œì„"]
    #
    #     if any(w in text for w in brain_words):
    #         parsed["category"] = parsed.get("category") or "ì†Œì…œ"
    #         parsed.setdefault("location_type", "INDOOR")
    #         # subcategoryëŠ” í™•ì •í•˜ì§€ ë§ê³ , í‚¤ì›Œë“œë¡œ ìœ ë„
    #         kws = parsed.get("keywords") or []
    #         kws += ["ë³´ë“œê²Œì„", "ë°©íƒˆì¶œ", "í¼ì¦", "ì¶”ë¦¬"]
    #         parsed["keywords"] = list(dict.fromkeys(kws))  # ì¤‘ë³µ ì œê±°
    #         parsed["vibe"] = parsed.get("vibe") or "ì¦ê±°ìš´"
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0) or 0), 0.75)
    #         logger.info("[POST_FIX] ë¨¸ë¦¬/ë‘ë‡Œ ì˜ë„ ê°ì§€ â†’ keywords í™•ì¥(ë³´ë“œê²Œì„/ë°©íƒˆì¶œ/í¼ì¦/ì¶”ë¦¬)")
    #         return parsed
    #
    #     # ê³µë†€ì´: êµ¬ì²´ ì¢…ëª©ì´ ì•„ë‹ˆë¼ì„œ subcategory ê°•ì œ ê¸ˆì§€
    #     if "ê³µë†€ì´" in text:
    #         parsed["category"] = "ìŠ¤í¬ì¸ "
    #         parsed.pop("subcategory", None)
    #         # í•µì‹¬: ê³µë†€ì´ -> ì¢…ëª© í‚¤ì›Œë“œë¡œ ì¹˜í™˜
    #         parsed["keywords"] = ["ì¶•êµ¬", "í’‹ì‚´", "ë†êµ¬", "ë°°ë“œë¯¼í„´", "í…Œë‹ˆìŠ¤"]
    #         parsed["confidence"] = min(float(parsed.get("confidence", 0) or 0), 0.65)
    #         logger.info("[POST_FIX] ê³µë†€ì´ ê°ì§€ â†’ keywordsë¥¼ êµ¬ì²´ ì¢…ëª©ìœ¼ë¡œ í™•ì¥(ëŸ¬ë‹ ëˆŒëŸ¬ì£¼ê¸°)")
    #         return parsed
    #
    #     # âœ… [NEW] ëŒ„ìŠ¤/ì¶¤ ì˜ë„ ê°•ì œ
    #     dance_words = ["ì¶¤", "ëŒ„ìŠ¤", "dance", "kpop", "k-pop", "ì¼€ì´íŒ", "ìŠ¤íŠ¸ë¦¿", "í™í•©ëŒ„ìŠ¤", "ë°©ì†¡ëŒ„ìŠ¤"]
    #     if any(w in text for w in dance_words):
    #         parsed["category"] = "ì·¨ë¯¸í™œë™"
    #         parsed["subcategory"] = "ëŒ„ìŠ¤"
    #         parsed["vibe"] = parsed.get("vibe") or "ì¦ê±°ìš´"
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0) or 0), 0.75)
    #
    #         # ë³´í†µ ëŒ„ìŠ¤ëŠ” ì‹¤ë‚´ê°€ ë§ìœ¼ë‹ˆ ê¸°ë³¸ê°’ë§Œ ì‚´ì§
    #         parsed.setdefault("location_type", "INDOOR")
    #
    #         logger.info("[POST_FIX] ì¶¤/ëŒ„ìŠ¤ ê°ì§€ â†’ category=ì·¨ë¯¸í™œë™, subcategory=ëŒ„ìŠ¤")
    #         return parsed
    #
    #     hands_on_words = ["ì†ìœ¼ë¡œ", "ë§Œë“¤", "ë§Œë“¤ê¸°", "ê³µë°©", "ì²´í—˜", "diy", "ìˆ˜ê³µì˜ˆ", "í•¸ë“œë©”ì´ë“œ"]
    #     if any(w in text for w in hands_on_words):
    #         parsed["category"] = "ì·¨ë¯¸í™œë™"
    #         parsed["vibe"] = parsed.get("vibe") or "ì—¬ìœ ë¡œìš´"
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0) or 0), 0.7)
    #
    #         # subcategoryë¥¼ í™•ì •í•  ë‹¨ì„œê°€ ìˆìœ¼ë©´ ì§€ì •
    #         if any(w in text for w in ["ë¶“ê¸€ì”¨", "ìº˜ë¦¬"]):
    #             parsed["subcategory"] = "ìº˜ë¦¬ê·¸ë¼í”¼"
    #
    #         logger.info("[POST_FIX] ì†ìœ¼ë¡œ/ê³µë°©/DIY ê°ì§€ â†’ category=ì·¨ë¯¸í™œë™")
    #         return parsed
    #
    #     # âœ… 0) "ë¨¹ëŠ”ê±°ë§ê³ " ê°™ì€ ì œì™¸ ì˜ë„ ë¨¼ì € ì²˜ë¦¬ (ë§›ì§‘ ê°•ì œ ì°¨ë‹¨)
    #     if self._excludes_food(text):
    #         # ë¨¹ëŠ” ê±´ ì œì™¸ë‹ˆê¹Œ, ìŒì‹/ì¹´í˜ ê³„ì—´ë¡œ ê°€ì§€ ì•Šê²Œ ë§‰ê¸°
    #         if parsed.get("category") in ["ë§›ì§‘", "ì¹´í˜"]:
    #             parsed.pop("category", None)
    #             parsed.pop("subcategory", None)
    #
    #         # ì‹¤ë‚´ë¥¼ ì›í•˜ë©´: ë¬¸í™”ì˜ˆìˆ /ì·¨ë¯¸í™œë™/ì†Œì…œ ìª½ìœ¼ë¡œ ìœ ë„
    #         # (êµ¬ì²´ í™œë™ ì—†ìœ¼ë©´ ë¬¸í™”ì˜ˆìˆ  defaultê°€ ë¬´ë‚œ)
    #         parsed.setdefault("location_type", "INDOOR")
    #         if not parsed.get("category"):
    #             parsed["category"] = "ë¬¸í™”ì˜ˆìˆ "
    #             parsed["vibe"] = parsed.get("vibe") or "ì—¬ìœ ë¡œìš´"
    #
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0) or 0), 0.65)
    #
    #         # keywordsì—ì„œ ìŒì‹ ê´€ë ¨ ì œê±° (ìˆë‹¤ë©´)
    #         kws = parsed.get("keywords") or []
    #         bad = {"ë¨¹", "ë¨¹ê¸°", "ì‹ì‚¬", "ë°¥", "ë§›ì§‘", "ì¹´í˜", "ë¸ŒëŸ°ì¹˜", "ë””ì €íŠ¸", "ìŒì‹"}
    #         parsed["keywords"] = [k for k in kws if str(k).strip() not in bad]
    #
    #         logger.info("[POST_FIX] 'ë¨¹ëŠ”ê±°ë§ê³ ' ì œì™¸ ì˜ë„ ê°ì§€ â†’ ìŒì‹ê³„ì—´ ì°¨ë‹¨, category=%s", parsed.get("category"))
    #         return parsed
    #
    #     # âœ… [ìµœìš°ì„ ] "ë¬¸í™”ìƒí™œ"ì€ ë¬´ì¡°ê±´ ë¬¸í™”ì˜ˆìˆ ë¡œ ë³¸ë‹¤ (ëŸ¬ë‹/ìš´ë™ ë°©ì§€)
    #     culture_words = ["ë¬¸í™”ìƒí™œ", "ì „ì‹œ", "ê³µì—°", "ë®¤ì§€ì»¬", "ì—°ê·¹", "ê°¤ëŸ¬ë¦¬", "ë°•ë¬¼ê´€", "ì‚¬ì§„ì „", "í˜ìŠ¤í‹°ë²Œ"]
    #     sports_words = ["ëŸ¬ë‹", "ìš´ë™", "ë›°", "ë‹¬ë¦¬", "ì¶•êµ¬", "ë°°ë“œë¯¼í„´", "í´ë¼ì´ë°", "ë“±ì‚°"]
    #
    #     if any(w in text for w in culture_words) and not any(w in text for w in sports_words):
    #         parsed["category"] = "ë¬¸í™”ì˜ˆìˆ "
    #         parsed.pop("subcategory", None)  # í•„ìš”í•˜ë©´ "ì „ì‹œíšŒ" ê°™ì€ê±¸ë¡œ ë„£ì–´ë„ ë¨
    #         parsed["vibe"] = parsed.get("vibe") or "ì—¬ìœ ë¡œìš´"
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0) or 0), 0.7)
    #         # location_typeì€ ì‹¤ì™¸/ì‹¤ë‚´ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì•„ë˜ ë¡œì§ì´ ì¡ì•„ì¤Œ
    #         logger.info("[POST_FIX] ë¬¸í™”ìƒí™œ ê°ì§€ â†’ category=ë¬¸í™”ì˜ˆìˆ  ê°•ì œ")
    #         return parsed
    #
    #     # âœ… 1. "ë†€ë‹¤" í‚¤ì›Œë“œ ìš°ì„  ì²´í¬ (ì‹ì‚¬ë³´ë‹¤ ìš°ì„ !)
    #     play_keywords = ["ë†€", "ì¬ë°Œê²Œ", "ì¦ê²ê²Œ", "ì‹ ë‚˜ê²Œ", "fun"]
    #     has_play = any(k in text for k in play_keywords)
    #
    #     # âœ… 2. ì‹ì‚¬ í‚¤ì›Œë“œëŠ” "ë¨¹ë‹¤" ê´€ë ¨ë§Œ
    #     meal_keywords = ["ë¨¹", "ì‹ì‚¬", "ë°¥", "ì ì‹¬ë¨¹", "ì €ë…ë¨¹", "ì•„ì¹¨ë¨¹"]  # "ì ì‹¬", "ì €ë…", "ì•„ì¹¨" ì œê±°!
    #     has_meal = any(k in text for k in meal_keywords)
    #
    #     # âœ… 3. "ë†€ë‹¤"ê°€ ìˆìœ¼ë©´ ì†Œì…œ ìš°ì„ 
    #     if has_play and not parsed.get("category"):
    #         parsed["category"] = "ì†Œì…œ"
    #         parsed["vibe"] = "ì¦ê±°ìš´"
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.65)
    #         logger.info(f"[POST_FIX] ë†€ì´ í‚¤ì›Œë“œ ê°ì§€ â†’ category=ì†Œì…œ")
    #         return parsed  # âœ… ì—¬ê¸°ì„œ ë°”ë¡œ ë¦¬í„´ (ì‹ì‚¬ ì²´í¬ ìŠ¤í‚µ)
    #
    #     # ì‹ì‚¬ í‚¤ì›Œë“œ ì²´í¬ (ë†€ì´ í‚¤ì›Œë“œ ì—†ì„ ë•Œë§Œ)
    #     if has_meal and not parsed.get("category"):
    #         parsed["category"] = "ë§›ì§‘"
    #         parsed["vibe"] = "ìºì£¼ì–¼"
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.6)
    #         logger.info(f"[POST_FIX] ì‹ì‚¬ í‚¤ì›Œë“œ â†’ category=ë§›ì§‘")
    #
    #     # âœ… ì‹œê°„ í‚¤ì›Œë“œë§Œ ìˆì„ ë•Œ category ì¶”ë¡ 
    #     time_only_keywords = ["ì£¼ë§", "í† ìš”ì¼", "ì¼ìš”ì¼", "í‰ì¼", "ì£¼ì¤‘"]
    #     has_time_keyword = any(k in text for k in time_only_keywords)
    #
    #     meal_keywords = ["ì ì‹¬", "ì €ë…", "ì•„ì¹¨", "ì‹ì‚¬", "ë¨¹"]
    #     has_meal = any(k in text for k in meal_keywords)
    #
    #     # âœ… ìƒˆë¡œ ì¶”ê°€: "ë‚˜ê°€ë‹¤" í‘œí˜„ ê°ì§€
    #     go_out_keywords = ["ë‚˜ê°€", "ì™¸ì¶œ", "ë‚˜ê°ˆ"]
    #     has_go_out = any(k in text for k in go_out_keywords)
    #
    #     if has_go_out and not parsed.get("location_type"):
    #         parsed["location_type"] = "OUTDOOR"
    #
    #         # category ë³´ì • (ì†Œì…œ â†’ ìŠ¤í¬ì¸  or ë¬¸í™”ì˜ˆìˆ )
    #         if parsed.get("category") == "ì†Œì…œ":
    #             # vibeë¡œ êµ¬ë¶„
    #             vibe = parsed.get("vibe", "")
    #             if vibe in ["ì¡°ìš©í•œ", "ì—¬ìœ ë¡œìš´", "íë§"]:
    #                 parsed["category"] = "ë¬¸í™”ì˜ˆìˆ "
    #                 parsed["subcategory"] = "ì‚°ì±…"
    #             else:
    #                 parsed["category"] = "ìŠ¤í¬ì¸ "
    #                 parsed["subcategory"] = "ëŸ¬ë‹"
    #
    #         # keywords ì •ë¦¬
    #         kws = parsed.get("keywords") or []
    #         # "ë‚˜ê°€ê³ ì‹¶ë‹¤", "ì†Œì…œ" ê°™ì€ ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì œê±°
    #         bad = {"ë‚˜ê°€ê³ ì‹¶ë‹¤", "ì™¸ì¶œ", parsed.get("category")}
    #         bad |= set(go_out_keywords)  # ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸°
    #         parsed["keywords"] = [k for k in kws if k not in bad]
    #
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.6)
    #         logger.info(f"[POST_FIX] 'ë‚˜ê°€ë‹¤' í‘œí˜„ ê°ì§€ â†’ location_type=OUTDOOR, category={parsed.get('category')}")
    #
    #     # âœ… "ì‹¤ì™¸ + ì¡°ìš©í•¨" ì¡°í•© ê°ì§€
    #     quiet_keywords = ["ì¡°ìš©", "ì”ì”", "ì—¬ìœ ", "í‰í™”", "ì°¨ë¶„"]
    #     has_quiet = any(k in text for k in quiet_keywords)
    #
    #     intense_keywords = ["ê²©ì •", "ê²©ë ¬", "ì—´ì •", "ê°•ë ¬", "í•˜ë“œì½”ì–´", "ìµìŠ¤íŠ¸ë¦¼"]
    #     has_intense = any(k in text for k in intense_keywords)
    #
    #     if has_intense:
    #         # âœ… ë¬´ì¡°ê±´ ìŠ¤í¬ì¸ ë¡œ ë³€ê²½
    #         parsed["category"] = "ìŠ¤í¬ì¸ "
    #         parsed["vibe"] = "ê²©ë ¬í•œ"
    #
    #         # âœ… ì‹¤ì™¸ë©´ subcategory ì¶”ë¡ 
    #         if parsed.get("location_type") == "OUTDOOR":
    #             # ëŸ¬ë‹/í´ë¼ì´ë°/ì¶•êµ¬ ë“± ì‹¤ì™¸ ìŠ¤í¬ì¸ 
    #             if "ë›°" in text or "ë‹¬ë¦¬" in text:
    #                 parsed["subcategory"] = "ëŸ¬ë‹"
    #             elif "ì˜¬ë¼" in text or "ë“±ë°˜" in text:
    #                 parsed["subcategory"] = "í´ë¼ì´ë°"
    #             else:
    #                 parsed["subcategory"] = None  # ì¼ë°˜ ìŠ¤í¬ì¸ 
    #
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.7)
    #         logger.info(f"[POST_FIX] ê²©ì •ì  ê°ì§€ â†’ category=ìŠ¤í¬ì¸ , vibe=ê²©ë ¬í•œ")
    #
    #     # âœ… ìƒˆë¡œ ì¶”ê°€: "ì‹¤ë‚´ + í¸ì•ˆí•¨" ì¡°í•© ì²˜ë¦¬
    #     indoor = parsed.get("location_type") == "INDOOR"
    #     quiet_keywords = ["í¸ì•ˆ", "ì—¬ìœ ", "ì¡°ìš©", "ì°¨ë¶„", "íë§", "í¸í•˜ê²Œ"]
    #     has_quiet = any(k in text for k in quiet_keywords)
    #
    #     if indoor and has_quiet and not parsed.get("category"):
    #         # âœ… ì‹¤ë‚´ì—ì„œ í¸ì•ˆí•˜ê²Œ â†’ ì¹´í˜/ë¬¸í™”ì˜ˆìˆ 
    #         if "ê³µë¶€" in text or "ìŠ¤í„°ë””" in text or "ì§‘ì¤‘" in text:
    #             parsed["category"] = "ìŠ¤í„°ë””"
    #             parsed["vibe"] = "ì§‘ì¤‘"
    #         else:
    #             parsed["category"] = "ì¹´í˜"  # ê¸°ë³¸ê°’
    #             parsed["vibe"] = "ì—¬ìœ ë¡œìš´"
    #
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.6)
    #         logger.info(f"[POST_FIX] ì‹¤ë‚´+í¸ì•ˆ â†’ category={parsed['category']}")
    #
    #     if parsed.get("location_type") == "OUTDOOR" and has_quiet:
    #         # ì†Œì…œ â†’ ë¬¸í™”ì˜ˆìˆ  ë³€ê²½
    #         if parsed.get("category") == "ì†Œì…œ":
    #             parsed["category"] = "ë¬¸í™”ì˜ˆìˆ "
    #             parsed["subcategory"] = "ì‚¬ì§„ì´¬ì˜"
    #             parsed["vibe"] = "ì¡°ìš©í•œ"
    #             parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.65)
    #             logger.info(f"[POST_FIX] ì‹¤ì™¸+ì¡°ìš© â†’ category=ë¬¸í™”ì˜ˆìˆ ")
    #
    #     # categoryê°€ ì—†ëŠ”ë° ì‹œê°„ í‚¤ì›Œë“œë§Œ ìˆìœ¼ë©´
    #     if has_time_keyword and not parsed.get("category"):
    #         # âœ… ìœ ì € ê´€ì‹¬ì‚¬ ê¸°ë°˜ ì¶”ë¡ 
    #         user_interests = parsed.get("user_interests", "").lower()
    #
    #         if "ì•„ì›ƒë„ì–´" in user_interests or "ìŠ¤í¬ì¸ " in user_interests:
    #             parsed["category"] = "ìŠ¤í¬ì¸ "
    #             parsed["vibe"] = "í™œê¸°ì°¬"
    #             parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.55)
    #             logger.info(f"[POST_FIX] ì£¼ë§+ìŠ¤í¬ì¸  ê´€ì‹¬ì‚¬ â†’ category=ìŠ¤í¬ì¸ ")
    #
    #         elif "ì†Œì…œ" in user_interests or "ê²Œì„" in user_interests:
    #             parsed["category"] = "ì†Œì…œ"
    #             parsed["vibe"] = "ì¦ê±°ìš´"
    #             parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.55)
    #             logger.info(f"[POST_FIX] ì£¼ë§+ì†Œì…œ ê´€ì‹¬ì‚¬ â†’ category=ì†Œì…œ")
    #
    #         elif "ì¹´í˜" in user_interests or "ë¬¸í™”" in user_interests:
    #             parsed["category"] = "ì¹´í˜"
    #             parsed["vibe"] = "ì—¬ìœ ë¡œìš´"
    #             parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.55)
    #             logger.info(f"[POST_FIX] ì£¼ë§+ì¹´í˜ ê´€ì‹¬ì‚¬ â†’ category=ì¹´í˜")
    #
    #         else:
    #             # âœ… ê¸°ë³¸ê°’: ì†Œì…œ (ì£¼ë§ì€ ë³´í†µ ì‚¬ëŒ ë§Œë‚˜ëŠ” í™œë™)
    #             parsed["category"] = "ì†Œì…œ"
    #             parsed["vibe"] = "ì¦ê±°ìš´"
    #             parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.5)
    #             logger.info(f"[POST_FIX] ì£¼ë§ ê¸°ë³¸ê°’ â†’ category=ì†Œì…œ")
    #
    #     # âœ… ì‹ì‚¬ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ë§›ì§‘
    #     if has_meal and not parsed.get("category"):
    #         parsed["category"] = "ë§›ì§‘"
    #         parsed["vibe"] = "ìºì£¼ì–¼"
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.6)
    #         logger.info(f"[POST_FIX] ì‹ì‚¬ í‚¤ì›Œë“œ â†’ category=ë§›ì§‘")
    #
    #     # âœ… 1. ìœ„ì¹˜ ì „ìš© ì¿¼ë¦¬ ê°ì§€ ("ì§‘ ê·¼ì²˜ì—ì„œ", "ì£¼ë³€", "ê°•ë‚¨ ê·¼ì²˜")
    #     location_only_keywords = ["ê·¼ì²˜", "ì£¼ë³€"]
    #     is_location_only = any(k in text for k in location_only_keywords)
    #
    #     # âœ… êµ¬ì²´ì  í™œë™ì´ ì—†ìœ¼ë©´ ìœ„ì¹˜ ì „ìš©ìœ¼ë¡œ íŒë‹¨
    #     activity_keywords = [
    #         "ì¹´í˜", "ëŸ¬ë‹", "ìš´ë™", "ë§›ì§‘", "ì „ì‹œ", "ìŠ¤í„°ë””", "ë†€", "ë¨¹",
    #         "ë³´ë“œê²Œì„", "ë‹¹êµ¬", "ì˜í™”", "í´ë¼ì´ë°", "ë°°ë“œë¯¼í„´", "ì¶•êµ¬"
    #     ]
    #     has_activity = any(k in text for k in activity_keywords)
    #
    #     if is_location_only and not has_activity:
    #         # GPTê°€ ë©‹ëŒ€ë¡œ ë¶™ì¸ category ì œê±°
    #         parsed.pop("category", None)
    #         parsed.pop("subcategory", None)
    #
    #         # location_query ëª…ì‹œì  ì„¤ì •
    #         if not parsed.get("location_query"):
    #             # "ì§‘ ê·¼ì²˜ì—ì„œ" â†’ "ì§‘ ê·¼ì²˜"
    #             if "ì§‘" in text:
    #                 parsed["location_query"] = "ì§‘ ê·¼ì²˜"
    #             else:
    #                 # "ê°•ë‚¨ ê·¼ì²˜" ê°™ì€ ê²½ìš° ì¶”ì¶œ
    #                 words = text.split()
    #                 for i, word in enumerate(words):
    #                     if any(loc in word for loc in location_only_keywords):
    #                         if i > 0:
    #                             parsed["location_query"] = words[i - 1]
    #                             break
    #
    #         # keywordsë„ ì •ë¦¬ (location ê´€ë ¨ë§Œ ë‚¨ê¸°ê¸°)
    #         kws = parsed.get("keywords") or []
    #         parsed["keywords"] = [k for k in kws if k in ["ì§‘", "ê°•ë‚¨", "í™ëŒ€", "ì„±ìˆ˜", "ì••êµ¬ì •"]]
    #
    #         logger.info(f"[POST_FIX] ìœ„ì¹˜ ì „ìš© ì¿¼ë¦¬ ê°ì§€ â†’ location_query={parsed.get('location_query')}, category ì œê±°")
    #
    #     # âœ… 2. location_type ê°•í™” (ëª…ì‹œì  í‚¤ì›Œë“œë§Œ)
    #     outdoor_keywords = ["ì‹¤ì™¸", "ì•¼ì™¸", "ë°–", "ì•„ì›ƒë„ì–´", "outdoor"]
    #     indoor_keywords = ["ì‹¤ë‚´", "ì¸ë„ì–´", "indoor"]  # âŒ "ì•ˆ" ì œê±°!
    #
    #     has_outdoor = any(k in text for k in outdoor_keywords)
    #     has_indoor = any(k in text for k in indoor_keywords)
    #
    #     # ìš°ì„ ìˆœìœ„: ì‹¤ì™¸/ì‹¤ë‚´ ëª…ì‹œ > GPT íŒŒì‹±ê°’
    #     if has_outdoor and not has_indoor:
    #         parsed["location_type"] = "OUTDOOR"
    #         logger.info(f"[POST_FIX] OUTDOOR ê°ì§€")
    #     elif has_indoor and not has_outdoor:
    #         parsed["location_type"] = "INDOOR"
    #         logger.info(f"[POST_FIX] INDOOR ê°ì§€")
    #     elif has_outdoor and has_indoor:
    #         # ë‘˜ ë‹¤ ìˆìœ¼ë©´ ë¨¼ì € ë‚˜ì˜¨ í‚¤ì›Œë“œ ìš°ì„ 
    #         outdoor_pos = min((text.find(k) for k in outdoor_keywords if k in text), default=999)
    #         indoor_pos = min((text.find(k) for k in indoor_keywords if k in text), default=999)
    #
    #         if outdoor_pos < indoor_pos:
    #             parsed["location_type"] = "OUTDOOR"
    #             logger.info(f"[POST_FIX] OUTDOOR ìš°ì„ ")
    #         else:
    #             parsed["location_type"] = "INDOOR"
    #             logger.info(f"[POST_FIX] INDOOR ìš°ì„ ")
    #
    #     # âœ… 3. ê¸°ì¡´ empty ë³´ì • (ìœ ì§€)
    #     empty = (not parsed.get("category")) and (not parsed.get("keywords"))
    #     if empty:
    #         play_intent = any(k in text for k in ["ë†€", "ë­í•˜ì§€", "í• ê±°ì—†", "ì‹¬ì‹¬", "ê¸°ë¶„ì „í™˜"])
    #
    #         if play_intent and parsed.get("location_type") == "INDOOR":
    #             parsed["category"] = "ì†Œì…œ"
    #             parsed["vibe"] = "ì¦ê±°ìš´"
    #             parsed["confidence"] = max(float(parsed.get("confidence", 0) or 0), 0.5)
    #             logger.info(f"[POST_FIX] ì‹¤ë‚´ ë†€ì´ ì˜ë„ ê°ì§€ â†’ category=ì†Œì…œ")
    #
    #         elif play_intent and parsed.get("location_type") == "OUTDOOR":
    #             parsed["category"] = "ìŠ¤í¬ì¸ "
    #             parsed["vibe"] = "í™œê¸°ì°¬"
    #             parsed["confidence"] = max(float(parsed.get("confidence", 0) or 0), 0.5)
    #             logger.info(f"[POST_FIX] ì‹¤ì™¸ í™œë™ ì˜ë„ ê°ì§€ â†’ category=ìŠ¤í¬ì¸ ")
    #
    #     morning_keywords = ["ì•„ì¹¨", "ì¡°ì‹", "ë¸ŒëŸ°ì¹˜", "morning"]
    #     has_morning = any(k in text for k in morning_keywords)
    #
    #     # categoryë¥¼ ìƒˆë¡œ ë§Œë“¤ì–´ë‚¼ ë•ŒëŠ” confidence ê°€ë“œ
    #     if parsed.get("category") and float(parsed.get("confidence", 0)) < 0.6:
    #         parsed.pop("category", None)
    #         parsed.pop("subcategory", None)
    #
    #     if has_morning and parsed.get("category") == "ë§›ì§‘":
    #         # ë§›ì§‘ â†’ ì¹´í˜(ë¸ŒëŸ°ì¹˜)ë¡œ ë³€ê²½
    #         parsed["category"] = "ì¹´í˜"
    #         parsed["subcategory"] = "ë¸ŒëŸ°ì¹˜"
    #         parsed["vibe"] = "ì—¬ìœ ë¡œìš´"
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.65)
    #         logger.info(f"[POST_FIX] ì•„ì¹¨ í‚¤ì›Œë“œ ê°ì§€ â†’ category=ì¹´í˜, subcategory=ë¸ŒëŸ°ì¹˜")
    #
    #     # ê³µë¶€ í‚¤ì›Œë“œ ë³´ì •
    #     study_keywords = ["ê³µë¶€", "ìŠ¤í„°ë””", "ì§‘ì¤‘", "ë…ì„œ", "í˜¼ì"]
    #     has_study = any(k in text for k in study_keywords)
    #
    #     if has_study and parsed.get("category") == "ì†Œì…œ":
    #         # ì†Œì…œ â†’ ìŠ¤í„°ë””ë¡œ ë³€ê²½
    #         parsed["category"] = "ìŠ¤í„°ë””"
    #         parsed["vibe"] = "ì§‘ì¤‘"
    #         parsed["confidence"] = max(float(parsed.get("confidence", 0)), 0.65)
    #         logger.info(f"[POST_FIX] ê³µë¶€ í‚¤ì›Œë“œ ê°ì§€ â†’ category=ìŠ¤í„°ë””")
    #
    #     return parsed

    def _post_fix(self, user_prompt: str, parsed: dict) -> dict:
        """
        GPT íŒŒì‹± í›„ ë³´ì • (ë¦¬íŒ©í„°)
        - ì¡°ê¸° return ì œê±°
        - ìš°ì„ ìˆœìœ„ ë£°ì„ ìœ„â†’ì•„ë˜ë¡œ ì ìš©
        - ê°•ì œ ë£° / ì†Œí”„íŠ¸ ë£° ë¶„ë¦¬
        """
        text = (user_prompt or "").lower().strip()
        q = dict(parsed or {})

        # -------------------------
        # helpers
        # -------------------------
        def set_if_empty(key: str, value):
            if not q.get(key):
                q[key] = value

        def bump_conf(min_conf: float):
            q["confidence"] = max(float(q.get("confidence", 0) or 0), float(min_conf))

        def add_keywords(words: list[str], limit: int = 8):
            kws = q.get("keywords") or []
            kws = [str(x).strip() for x in kws if x]
            for w in words:
                w = str(w).strip()
                if w and w not in kws:
                    kws.append(w)
            q["keywords"] = kws[:limit]

        def drop_food_keywords():
            kws = q.get("keywords") or []
            bad = {"ë¨¹", "ë¨¹ê¸°", "ì‹ì‚¬", "ë°¥", "ë§›ì§‘", "ì¹´í˜", "ë¸ŒëŸ°ì¹˜", "ë””ì €íŠ¸", "ìŒì‹"}
            q["keywords"] = [k for k in kws if str(k).strip() not in bad]

        # -------------------------
        # 0) location_type ëª…ì‹œ í‚¤ì›Œë“œë§Œ ë¨¼ì € í™•ì • (ì‹¤ë‚´/ì‹¤ì™¸)
        # -------------------------
        outdoor_keywords = ["ì‹¤ì™¸", "ì•¼ì™¸", "ë°–", "ì•„ì›ƒë„ì–´", "outdoor"]
        indoor_keywords = ["ì‹¤ë‚´", "ì¸ë„ì–´", "indoor"]

        has_outdoor = any(k in text for k in outdoor_keywords)
        has_indoor = any(k in text for k in indoor_keywords)

        if has_outdoor and not has_indoor:
            q["location_type"] = "OUTDOOR"
        elif has_indoor and not has_outdoor:
            q["location_type"] = "INDOOR"
        elif has_outdoor and has_indoor:
            # ë‘˜ ë‹¤ ìˆìœ¼ë©´ ë¨¼ì € ë‚˜ì˜¨ í‚¤ì›Œë“œ ìš°ì„ 
            outdoor_pos = min((text.find(k) for k in outdoor_keywords if k in text), default=999)
            indoor_pos = min((text.find(k) for k in indoor_keywords if k in text), default=999)
            q["location_type"] = "OUTDOOR" if outdoor_pos < indoor_pos else "INDOOR"

        # -------------------------
        # âœ… 0.5) "ì‹¤ë‚´ì—ì„œ ì¦ê²ê²Œ/ì¬ë°Œê²Œ/ì‹ ë‚˜ê²Œ" ê°™ì€ vibe-only ìš”ì²­ì€
        # ì¹´í˜ë¡œ ì ë¦¬ê¸° ì‰¬ìš°ë‹ˆ ê¸°ë³¸ì„ 'ì†Œì…œ(ë³´ë“œê²Œì„/ë°©íƒˆì¶œ)'ë¡œ êµì •
        # - í™œë™ ë‹¨ì„œê°€ ì—†ì„ ë•Œë§Œ ë°œë™ (ë®ì–´ì“°ê¸° ë°©ì§€)
        # - GPTê°€ ì¹´í˜ë¡œ ì°ì–´ë„ ì—¬ê¸°ì„œ ì¡ì•„ì¤Œ
        # -------------------------
        fun_words = ["ì¦ê²", "ì¬ë°Œ", "ì¬ë¯¸", "ì‹ ë‚˜", "fun"]
        indoor_fun = (q.get("location_type") == "INDOOR") and any(w in text for w in fun_words)

        # í™œë™ ë‹¨ì„œ(ëª…ì‚¬)ê°€ ê±°ì˜ ì—†ìœ¼ë©´: vibe-onlyë¡œ íŒì •
        activity_hints = [
            "ë³´ë“œê²Œì„", "ë°©íƒˆì¶œ", "ì²´ìŠ¤", "í¼ì¦", "í€´ì¦ˆ",
            "ëŸ¬ë‹", "ì¶•êµ¬", "ë°°ë“œë¯¼í„´", "í´ë¼ì´ë°", "ë“±ì‚°", "ìš´ë™",
            "ì „ì‹œ", "ê³µì—°", "ë®¤ì§€ì»¬", "ì—°ê·¹", "ê°¤ëŸ¬ë¦¬",
            "ì¹´í˜", "ë¸ŒëŸ°ì¹˜", "ë””ì €íŠ¸", "ë§›ì§‘",
            "ìŠ¤í„°ë””", "ê³µë¶€", "ë…ì„œ", "ì˜ì–´", "ì½”ë”©",
            "ëŒ„ìŠ¤", "ì¶¤", "ê³µë°©", "diy", "ë§Œë“¤ê¸°", "ìš”ë¦¬",
            "ë…¸ë˜ë°©", "ë³¼ë§", "ë‹¹êµ¬",
        ]
        has_activity_hint = any(h in text for h in activity_hints)
        kws_now = q.get("keywords") or []
        vibe_only = (not has_activity_hint) and (len(kws_now) == 0) and (not q.get("subcategory"))


        if indoor_fun and vibe_only:
            q["category"] = "ì†Œì…œ"
            q.pop("subcategory", None)
            add_keywords(["ë³´ë“œê²Œì„", "ë°©íƒˆì¶œ"], limit=10)
            # vibeëŠ” ìœ ì§€í•˜ë˜ conf ì‚´ì§ ì˜¬ë¦¼
            q["vibe"] = q.get("vibe") or "ì¦ê±°ìš´"
            q["confidence"] = max(float(q.get("confidence", 0) or 0), 0.65)

        # -------------------------
        # 1) "ë¨¹ëŠ”ê±° ë§ê³ /ì œì™¸" ìµœìš°ì„  (ë§›ì§‘/ì¹´í˜ ê°•ì œ ì°¨ë‹¨)
        # -------------------------
        if self._excludes_food(text):
            if q.get("category") in ["ë§›ì§‘", "ì¹´í˜"]:
                q.pop("category", None)
                q.pop("subcategory", None)
            set_if_empty("location_type", "INDOOR")
            set_if_empty("category", "ë¬¸í™”ì˜ˆìˆ ")
            set_if_empty("vibe", "ì—¬ìœ ë¡œìš´")
            bump_conf(0.65)
            drop_food_keywords()

        # -------------------------
        # 2) ì‚¬ì§„/ì´¬ì˜ ì˜ë„ ê°•ì œ
        # -------------------------
        photo_words = ["ì‚¬ì§„", "ì´¬ì˜", "í¬í† ", "ì¹´ë©”ë¼", "í•„ì¹´", "ìŠ¤ëƒ…", "ì¸ìƒìƒ·"]
        if any(w in text for w in photo_words):
            q["category"] = "ë¬¸í™”ì˜ˆìˆ "
            q["subcategory"] = "ì‚¬ì§„ì´¬ì˜"
            set_if_empty("vibe", "ì¦ê±°ìš´")
            bump_conf(0.75)

        # -------------------------
        # 3) ë‡Œ/ì¶”ë¦¬/ë³´ë“œê²Œì„ ê°•ì œ
        # -------------------------
        brain_words = ["ë¨¸ë¦¬", "ë¨¸ë¦¬ì“°", "ë‘ë‡Œ", "ì¶”ë¦¬", "ì „ëµ", "í¼ì¦", "í€´ì¦ˆ", "ë°©íƒˆì¶œ", "ë³´ë“œê²Œì„", "ì²´ìŠ¤"]
        if any(w in text for w in brain_words):
            set_if_empty("category", "ì†Œì…œ")
            set_if_empty("location_type", "INDOOR")
            add_keywords(["ë³´ë“œê²Œì„", "ë°©íƒˆì¶œ", "í¼ì¦", "ì¶”ë¦¬"], limit=10)
            set_if_empty("vibe", "ì¦ê±°ìš´")
            bump_conf(0.75)

        # -------------------------
        # 4) ê³µë†€ì´ ì²˜ë¦¬: subcategory ê°•ì œ ê¸ˆì§€ + ì¢…ëª© í‚¤ì›Œë“œ í™•ì¥
        # -------------------------
        if "ê³µë†€ì´" in text:
            q["category"] = "ìŠ¤í¬ì¸ "
            q.pop("subcategory", None)
            q["keywords"] = ["ì¶•êµ¬", "í’‹ì‚´", "ë†êµ¬", "ë°°ë“œë¯¼í„´", "í…Œë‹ˆìŠ¤"]
            bump_conf(0.65)

        # -------------------------
        # 5) ì¶¤/ëŒ„ìŠ¤ ê°•ì œ
        # -------------------------
        dance_words = ["ì¶¤", "ëŒ„ìŠ¤", "dance", "kpop", "k-pop", "ì¼€ì´íŒ", "ìŠ¤íŠ¸ë¦¿", "í™í•©ëŒ„ìŠ¤", "ë°©ì†¡ëŒ„ìŠ¤"]
        if any(w in text for w in dance_words):
            q["category"] = "ì·¨ë¯¸í™œë™"
            q["subcategory"] = "ëŒ„ìŠ¤"
            set_if_empty("vibe", "ì¦ê±°ìš´")
            set_if_empty("location_type", "INDOOR")
            bump_conf(0.75)

        # -------------------------
        # 6) ì†ìœ¼ë¡œ/ê³µë°©/DIY ê°•ì œ
        # -------------------------
        hands_on_words = ["ì†ìœ¼ë¡œ", "ë§Œë“¤", "ë§Œë“¤ê¸°", "ê³µë°©", "ì²´í—˜", "diy", "ìˆ˜ê³µì˜ˆ", "í•¸ë“œë©”ì´ë“œ"]
        if any(w in text for w in hands_on_words):
            q["category"] = "ì·¨ë¯¸í™œë™"
            set_if_empty("vibe", "ì—¬ìœ ë¡œìš´")
            bump_conf(0.70)
            if any(w in text for w in ["ë¶“ê¸€ì”¨", "ìº˜ë¦¬", "ìº˜ë¦¬ê·¸ë¼í”¼"]):
                q["subcategory"] = "ìº˜ë¦¬ê·¸ë¼í”¼"

        # -------------------------
        # 7) ë¬¸í™”ìƒí™œ(ìš´ë™/ìŠ¤í¬ì¸  ë‹¨ì„œ ì—†ìœ¼ë©´) â†’ ë¬¸í™”ì˜ˆìˆ  ê°•ì œ
        # -------------------------
        culture_words = ["ë¬¸í™”ìƒí™œ", "ì „ì‹œ", "ê³µì—°", "ë®¤ì§€ì»¬", "ì—°ê·¹", "ê°¤ëŸ¬ë¦¬", "ë°•ë¬¼ê´€", "ì‚¬ì§„ì „", "í˜ìŠ¤í‹°ë²Œ"]
        sports_words = ["ëŸ¬ë‹", "ìš´ë™", "ë›°", "ë‹¬ë¦¬", "ì¶•êµ¬", "ë°°ë“œë¯¼í„´", "í´ë¼ì´ë°", "ë“±ì‚°"]
        if any(w in text for w in culture_words) and not any(w in text for w in sports_words):
            q["category"] = "ë¬¸í™”ì˜ˆìˆ "
            q.pop("subcategory", None)
            set_if_empty("vibe", "ì—¬ìœ ë¡œìš´")
            bump_conf(0.70)

        # -------------------------
        # 8) "ë‚˜ê°€ê³ ì‹¶ë‹¤/ì™¸ì¶œ" ê°™ì€ í‘œí˜„: location_typeë§Œ OUTDOORë¡œ, ì¹´í…Œê³ ë¦¬ëŠ” ê°•ì œí•˜ì§€ ì•ŠìŒ(ë®ì–´ì“°ê¸° ë°©ì§€)
        # -------------------------
        go_out_keywords = ["ë‚˜ê°€", "ì™¸ì¶œ", "ë‚˜ê°ˆ"]
        if any(k in text for k in go_out_keywords):
            set_if_empty("location_type", "OUTDOOR")
            bump_conf(0.55)

        # -------------------------
        # 9) "ë†€ë‹¤" vs "ë¨¹ë‹¤" ìš°ì„ ìˆœìœ„ (ì¹´í…Œê³ ë¦¬ ë¹„ì–´ìˆì„ ë•Œë§Œ)
        # -------------------------
        play_keywords = ["ë†€", "ì¬ë°Œê²Œ", "ì¦ê²ê²Œ", "ì‹ ë‚˜ê²Œ", "fun"]
        meal_keywords = ["ë¨¹", "ì‹ì‚¬", "ë°¥", "ì ì‹¬ë¨¹", "ì €ë…ë¨¹", "ì•„ì¹¨ë¨¹"]

        has_play = any(k in text for k in play_keywords)
        has_meal = any(k in text for k in meal_keywords)

        if not q.get("category"):
            if has_play:
                q["category"] = "ì†Œì…œ"
                set_if_empty("vibe", "ì¦ê±°ìš´")
                bump_conf(0.65)
            elif has_meal:
                q["category"] = "ë§›ì§‘"
                set_if_empty("vibe", "ìºì£¼ì–¼")
                bump_conf(0.60)

        # -------------------------
        # 10) ìœ„ì¹˜-only ì¿¼ë¦¬ ê°ì§€: í™œë™ ë‹¨ì„œ ì—†ìœ¼ë©´ category/subcategory ì œê±°
        # -------------------------
        location_only_keywords = ["ê·¼ì²˜", "ì£¼ë³€"]
        activity_keywords = [
            "ì¹´í˜", "ëŸ¬ë‹", "ìš´ë™", "ë§›ì§‘", "ì „ì‹œ", "ìŠ¤í„°ë””", "ë†€", "ë¨¹",
            "ë³´ë“œê²Œì„", "ë‹¹êµ¬", "ì˜í™”", "í´ë¼ì´ë°", "ë°°ë“œë¯¼í„´", "ì¶•êµ¬"
        ]
        is_location_only = any(k in text for k in location_only_keywords)
        has_activity = any(k in text for k in activity_keywords)

        if is_location_only and not has_activity:
            q.pop("category", None)
            q.pop("subcategory", None)
            if not q.get("location_query"):
                if "ì§‘" in text:
                    q["location_query"] = "ì§‘ ê·¼ì²˜"
            bump_conf(0.55)

        # -------------------------
        # 11) ê³µë¶€/ìŠ¤í„°ë””: ì†Œì…œë¡œ ì˜ëª» ì°íˆë©´ ìŠ¤í„°ë””ë¡œ êµì •
        # -------------------------
        study_keywords = ["ê³µë¶€", "ìŠ¤í„°ë””", "ì§‘ì¤‘", "ë…ì„œ", "í˜¼ì"]
        if any(k in text for k in study_keywords):
            if q.get("category") == "ì†Œì…œ":
                q["category"] = "ìŠ¤í„°ë””"
            set_if_empty("vibe", "ì§‘ì¤‘")
            bump_conf(0.65)

        # -------------------------
        # 12) ì„±ë³„ í‚¤ì›Œë“œ: "ê°•ì œ ì¹´í…Œê³ ë¦¬ ë³€ê²½" ê¸ˆì§€(í¸í–¥/ë®ì–´ì“°ê¸° ë°©ì§€) â†’ í‚¤ì›Œë“œ íŒíŠ¸ë§Œ ì•½í•˜ê²Œ
        # -------------------------
        male_keywords = ["ë‚¨ì", "ë‚¨ì„±", "ë‚¨ìê°€", "ë‚¨ì„±ì´"]
        female_keywords = ["ì—¬ì", "ì—¬ì„±", "ì—¬ìê°€", "ì—¬ì„±ì´"]
        has_male = any(k in text for k in male_keywords)
        has_female = any(k in text for k in female_keywords)

        if has_male and not has_female:
            # ì¹´í…Œê³ ë¦¬ê°€ ë¹„ì–´ìˆê±°ë‚˜, ì†Œì…œ/ìŠ¤í¬ì¸ ì¼ ë•Œë§Œ íŒíŠ¸
            if q.get("category") in [None, "", "ì†Œì…œ", "ìŠ¤í¬ì¸ "]:
                add_keywords(["ì¶•êµ¬", "ë³¼ë§", "ë‹¹êµ¬"], limit=10)
                bump_conf(0.55)

        if has_female and not has_male:
            if q.get("category") in [None, "", "ì¹´í˜", "ë¬¸í™”ì˜ˆìˆ ", "ì·¨ë¯¸í™œë™"]:
                add_keywords(["ì¹´í˜", "ì „ì‹œ", "ê³µë°©"], limit=10)
                bump_conf(0.55)

        # -------------------------
        # 13) ë§ˆì§€ë§‰ safety: conf ë‚®ì€ë° "ìƒˆë¡œ ë§Œë“  category"ë©´ ì œê±° (ê¸°ì¡´ ë„ˆ ë¡œì§ ìœ ì§€í•˜ì§€ë§Œ ë” ì•ˆì „í•˜ê²Œ)
        # -------------------------
        conf = float(q.get("confidence", 0) or 0)
        if q.get("category") and conf < 0.55:
            # ë‹¨, ìœ„ì˜ ê°•ì œ ë£°(ì‚¬ì§„/ë‡Œ/ëŒ„ìŠ¤/ê³µë°©/ë¬¸í™”ìƒí™œ/ì œì™¸ì²˜ë¦¬ ë“±)ë¡œ ë§Œë“¤ì–´ì§„ ê²½ìš°ëŠ” ë‚¨ê¸°ê³  ì‹¶ìœ¼ë©´ í”Œë˜ê·¸ë¥¼ ë‘˜ ìˆ˜ ìˆìŒ
            # ì—¬ê¸°ì„œëŠ” ì•ˆì „ ìš°ì„ ìœ¼ë¡œ ìœ ì§€í•˜ì§€ ì•Šê³  ì œê±°í•˜ì§€ ì•ŠìŒ (ë„ˆ ê¸°ì¡´ì€ 0.6 ë¯¸ë§Œ ì œê±°ì˜€ëŠ”ë° ë„ˆë¬´ ê³µê²©ì ì¼ ìˆ˜ ìˆìŒ)
            pass

        return q

    """
    _apply_intent_adjustment() ìµœì¢… ì•½í™” ë²„ì „
    Location ë³´ì • +12 â†’ +6
    """

    def _apply_intent_adjustment(self, intent: str, meeting: dict, parsed_query: dict = None) -> float:
        cat = meeting.get("category") or ""
        sub = meeting.get("subcategory") or ""

        adjustment = 0.0

        # âœ… NEUTRALì€ ê°€ì‚°/ê°ì‚° ì—†ì´ 0ì´ ê¸°ë³¸ (íŠœë‹ ë‚œì´ë„ ê¸‰ê°)

        if not intent or intent == "NEUTRAL":
            # ë‹¨, location_type ëª…ì‹œ ìš”ì²­ë§Œì€ ì•½í•˜ê²Œ ë°˜ì˜í•˜ê³  ì‹¶ìœ¼ë©´ ì—¬ê¸°ì„œ ì²˜ë¦¬
            if parsed_query:
                requested_type = parsed_query.get("location_type")
                meeting_type = meeting.get("meeting_location_type") or meeting.get("location_type")
                if requested_type and meeting_type:
                    if requested_type.upper() == meeting_type.upper():
                        adjustment += 3.0
                    else:
                        adjustment -= 3.0

            return adjustment

        # âœ… ACTIVE intent ê°•í™”
        if intent == "ACTIVE":
            if cat == "ìŠ¤í¬ì¸ ":
                if sub == "ì¶•êµ¬":
                    adjustment += 18.0
                elif sub in ["ëŸ¬ë‹", "í´ë¼ì´ë°", "ë°°ë“œë¯¼í„´"]:
                    adjustment += 10.0
                else:
                    adjustment += 8.0
            else:
                # âœ… ìŠ¤í¬ì¸ ê°€ ì—†ì„ ë•ŒëŠ” ê³¼ë„í•œ íŒ¨ë„í‹° ê¸ˆì§€
                adjustment -= 6.0

        if intent == "HANDS_ON":
            if cat == "ì·¨ë¯¸í™œë™":
                adjustment += 12.0
            if cat == "ë¬¸í™”ì˜ˆìˆ ":
                adjustment += 6.0
            if cat == "ì†Œì…œ" and sub in ["ë‹¹êµ¬", "ë³¼ë§", " ê¸°ì–µ", "ë…¸ë˜ë°©", "ë³´ë“œê²Œì„"]:
                adjustment -= 18.0

        # âœ… ì¹´í˜/ë¬¸í™”ì˜ˆìˆ  ê°•í•˜ê²Œ íŒ¨ë„í‹°
        if intent == "ACTIVE" and cat in ["ì¹´í˜", "ë¬¸í™”ì˜ˆìˆ "]:
            adjustment -= 6.0

        if intent == "BRAIN":
            # ë³´ë“œê²Œì„/ë°©íƒˆì¶œì„ ìµœìš°ì„ ìœ¼ë¡œ ëŒì–´ì˜¬ë¦¼
            if cat == "ì†Œì…œ" and sub in ["ë³´ë“œê²Œì„", "ë°©íƒˆì¶œ"]:
                adjustment += 22.0
            # ë¨¸ë¦¬ì“°ëŠ” ìš”ì²­ì— ë‹¹êµ¬/ë³¼ë§/ì™€ì¸ë°”ëŠ” ê³¼ê°íˆ ë‚´ë¦¼
            if cat == "ì†Œì…œ" and sub in ["ë‹¹êµ¬", "ë³¼ë§", "ì™€ì¸ë°”", "ë…¸ë˜ë°©"]:
                adjustment -= 18.0
            # ì¹´í˜/ë¬¸í™”ì˜ˆìˆ ì€ ì¤‘ë¦½ ì •ë„
            if cat in ["ì¹´í˜", "ë¬¸í™”ì˜ˆìˆ "]:
                adjustment += 0.0

        # âœ… ì†Œì…œë„ ì•½ê°„ íŒ¨ë„í‹° (ë²„ìŠ¤í‚¹ íˆ¬ì–´ ì°¨ë‹¨)
        if intent == "ACTIVE" and cat == "ì†Œì…œ":
            if sub in ["ë³¼ë§", "ë‹¹êµ¬", "íƒêµ¬"]:
                adjustment += 3.0  # 6 â†’ 3ìœ¼ë¡œ ì•½í™”
            else:
                adjustment -= 6.0

        # âœ… QUIET intent (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
        if intent == "QUIET":
            if cat == "ìŠ¤í¬ì¸ ":
                adjustment += -30.0
            elif cat == "ì¹´í˜":
                adjustment += 15.0
            elif cat == "ë¬¸í™”ì˜ˆìˆ ":
                adjustment += 12.0

        keywords = (parsed_query.get("keywords") or []) if parsed_query else []
        if "ê³µë†€ì´" in keywords:
            if cat == "ìŠ¤í¬ì¸ " and sub == "ëŸ¬ë‹":
                adjustment -= 20.0
            if cat == "ìŠ¤í¬ì¸ " and sub in ["ì¶•êµ¬", "ë°°ë“œë¯¼í„´"]:
                adjustment += 10.0

        # âœ… location_type ë³´ì •
        if parsed_query:
            requested_type = parsed_query.get("location_type")
            meeting_type = meeting.get("meeting_location_type") or meeting.get("location_type")

            if requested_type and meeting_type:
                if requested_type.upper() == meeting_type.upper():
                    adjustment += 6.0
                else:
                    adjustment -= 10.0

        return adjustment

    def _is_adjacent_timeslot(self, slot1: str, slot2: str) -> bool:
        """ì¸ì ‘ ì‹œê°„ëŒ€ ì²´í¬ (ì•„ì¹¨â†”ì ì‹¬, ì ì‹¬â†”ì €ë… ë“±)"""
        if not slot1 or not slot2:
            return False

        adjacency = {
            "MORNING": ["AFTERNOON"],
            "AFTERNOON": ["MORNING", "EVENING"],
            "EVENING": ["AFTERNOON", "NIGHT"],
            "NIGHT": ["EVENING"]
        }

        return slot2 in adjacency.get(slot1, [])

    def _apply_vibe_prior(self, q: dict) -> dict:
        cat = q.get("category")
        sub = q.get("subcategory")
        kws = q.get("keywords") or []
        vibe = self._normalize_vibe(q.get("vibe"))
        lt = (q.get("location_type") or "").upper()
        conf = float(q.get("confidence", 0) or 0)

        if (not cat) and (not sub) and (len(kws) == 0) and vibe:
            if vibe in ["ì¦ê±°ìš´", "í™œê¸°ì°¬"]:
                q["category"] = "ì†Œì…œ"
                q["confidence"] = max(conf, 0.6)

            elif vibe in ["ê±´ê°•í•œ"]:
                q["category"] = "ìŠ¤í¬ì¸ "
                q["confidence"] = max(conf, 0.6)

            elif vibe in ["ì—¬ìœ ë¡œìš´", "íë§", "ê°ì„±ì ì¸"]:
                # âœ… í•µì‹¬: ì•¼ì™¸ + ì¡°ìš©/íë§ì´ë©´ ì¹´í˜ë³´ë‹¤ ì‚°ì±…/ì „ì‹œ/ì‚¬ì§„ì´ ë” ìì—°ìŠ¤ëŸ¬ì›€
                if lt == "OUTDOOR":
                    q["category"] = "ë¬¸í™”ì˜ˆìˆ "
                    # ìˆìœ¼ë©´ DBì— ë§ì¶°: "ì‚°ì±…" / "ì‚¬ì§„ì´¬ì˜"
                    q.pop("subcategory", None)
                else:
                    q["category"] = "ì¹´í˜"
                q["confidence"] = max(conf, 0.6)

        q["vibe"] = vibe
        return q

    def _pick_location_type_from_raw(self, m: dict) -> Optional[str]:
        # Spring AIMeetingDTOëŠ” @JsonProperty("location_type")ë¼ì„œ location_typeì´ ì£¼ë ¥
        return m.get("location_type") or m.get("locationType")

    def _pick_location_type_from_normalized(self, m: dict) -> Optional[str]:
        return m.get("meeting_location_type")

    def _has_explicit_timeslot(self, text: str) -> bool:
        t = (text or "").lower()
        return any(k in t for k in ["ì•„ì¹¨", "ì˜¤ì „", "ì ì‹¬", "ì˜¤í›„", "ì €ë…", "ë°¤", "ì•¼ê°„", "morning", "afternoon", "evening", "night"])

    def _has_explicit_quiet(self, text: str) -> bool:
        t = (text or "").lower()
        return any(w in t for w in ["ì¡°ìš©", "ì°¨ë¶„", "íë§", "ì”ì”", "ê³ ìš”"])

    def _has_explicit_location(self, user_prompt: str, q: dict | None = None) -> bool:
        text = (user_prompt or "").strip()
        if not text:
            return False

        # 1) near-me í‘œí˜„ì€ explicit_locë¡œ ì¹˜ì§€ ì•ŠìŒ (ê·¸ê±´ radius ë¡œì§ìœ¼ë¡œ ì²˜ë¦¬)
        if self._is_near_me_phrase(text):
            return False

        # 2) GPTê°€ location_queryë¥¼ ë½‘ì•„ì¤¬ê³ , ê·¸ ê°’ì´ near-meê°€ ì•„ë‹ˆë©´ ê±°ì˜ ëª…ì‹œ ì§€ëª…
        if q:
            lq = q.get("location_query") or q.get("locationQuery")
            if lq and not self._is_near_me_phrase(str(lq)):
                # "ê°•ë‚¨", "ì„±ìˆ˜", "ì ì‹¤", "í™ëŒ€ì…êµ¬" ë“±
                return True

        # 3) íœ´ë¦¬ìŠ¤í‹±: ì—­/ë™/êµ¬/ì‹œ/êµ°/ì/ë©´/ë¦¬/ë¡œ/ê¸¸ ë“± ì§€ëª… ì ‘ë¯¸
        # (ë„ˆí¬ ì„œë¹„ìŠ¤ê°€ ì„œìš¸ ìœ„ì£¼ë©´ 'ì—­/ë™/êµ¬'ë§Œìœ¼ë¡œë„ ì¶©ë¶„)
        patterns = [
            r"[ê°€-í£]{1,10}ì—­",  # ê°•ë‚¨ì—­, ì„±ìˆ˜ì—­
            r"[ê°€-í£]{1,10}ë™",  # ê¸¸ë™, ì„±ìˆ˜ë™
            r"[ê°€-í£]{1,10}êµ¬",  # ì†¡íŒŒêµ¬
            r"[ê°€-í£]{1,10}(ë¡œ|ê¸¸)",  # í…Œí—¤ë€ë¡œ, ì—°ë¬´ì¥ê¸¸ ë“±
        ]
        return any(re.search(p, text) for p in patterns)

    def _guard_category_by_evidence(self, user_prompt: str, q: dict) -> dict:

        def _has_any(text: str, words: list[str]) -> bool:
            t = (text or "").lower()
            return any(w in t for w in words)

        text = (user_prompt or "").lower()

        cat = (q.get("category") or "").strip()
        lt  = (q.get("location_type") or "").upper()

        # "ìŠ¤í„°ë””"ë¼ê³  ë¶€ë¥¼ë§Œí•œ ì¦ê±° ë‹¨ì–´ë“¤
        STUDY_EVIDENCE = ["ìŠ¤í„°ë””", "ê³µë¶€", "ë…ì„œ", "í† ìµ", "ì˜¤í”½", "ì˜ì–´", "ìê²©ì¦", "ì½”ë”©", "ê°œë°œ", "í”„ë¡œê·¸ë˜ë°", "ì„¸ë¯¸ë‚˜", "ê°•ì˜"]

        # "ì¡°ìš©/íë§"ë§Œ ë§í•œ ì¼€ì´ìŠ¤
        QUIET_EVIDENCE = ["ì¡°ìš©", "ì°¨ë¶„", "íë§", "ì”ì”", "ê³ ìš”", "ì—¬ìœ "]

        has_study = _has_any(text, STUDY_EVIDENCE)
        has_quiet = _has_any(text, QUIET_EVIDENCE)

        # âœ… í•µì‹¬: ìŠ¤í„°ë”” ì¦ê±°ê°€ ì—†ëŠ”ë° GPTê°€ ìŠ¤í„°ë””ë¡œ ì°ìœ¼ë©´ ì œê±°/êµì •
        if cat == "ìŠ¤í„°ë””" and not has_study:
            # ì„ íƒì§€ A) categoryë¥¼ ì œê±°í•´ì„œ "ì•¼ì™¸ + ì¡°ìš©"ë§Œìœ¼ë¡œ ë„“ê²Œ ì°¾ê¸°
            q.pop("category", None)
            q.pop("subcategory", None)

            # ì„ íƒì§€ B) ë„ˆ DBì— ë§ì¶° 'ë¬¸í™”ì˜ˆìˆ 'ë¡œ êµì • (ì•¼ì™¸ ì¡°ìš©ì´ë©´ ì‚°ì±…/ì‚¬ì§„ ìª½ì´ ìì—°ìŠ¤ëŸ¬ì›€)
            # q["category"] = "ë¬¸í™”ì˜ˆìˆ "
            # q.pop("subcategory", None)

            # í‚¤ì›Œë“œ íŒíŠ¸ ì¡°ê¸ˆ ì£¼ë©´ GPT/ë­í‚¹ì—ë„ ë„ì›€ ë¨ (DBì— ì—†ì–´ë„ query_terms ë³´ê°•ìš©)
            kws = q.get("keywords") or []
            for w in ["ì‚°ì±…", "ì‚¬ì§„", "í”¼í¬ë‹‰", "ê³µì›"]:
                if w not in kws:
                    kws.append(w)
            q["keywords"] = kws[:8]

            # confidence ë„ˆë¬´ ë†’ê²Œ ë¯¿ì§€ ë§ì
            q["confidence"] = min(float(q.get("confidence", 0) or 0), 0.65)

        # âœ… ì•¼ì™¸ + ì¡°ìš©ì¸ë° ì¹´í…Œê³ ë¦¬ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¬¸í™”ì˜ˆìˆ ë¡œ ê¸°ë³¸ê°’ ì£¼ëŠ” ê²ƒë„ ê°€ëŠ¥
        if (not q.get("category")) and lt == "OUTDOOR" and has_quiet:
            q["category"] = "ë¬¸í™”ì˜ˆìˆ "
            q["confidence"] = max(float(q.get("confidence", 0) or 0), 0.6)

        return q




